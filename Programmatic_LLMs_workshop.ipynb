{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Programmatic use of LLMs workshop\n",
        "The first step of programmatically using an LLM is to have a program to use it for! In part 1, we're going to just get used to the general concepts of using the LLM in a code interface. Then in part 2, we're going to write a program where we use a large language model to query information about an academic paper."
      ],
      "metadata": {
        "id": "vUT2F7r31V1T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 1: Let's say hi to an LLM!\n",
        "In this first part, we're going to set up our environment so that we can communicate with ChatGPT 4o-mini."
      ],
      "metadata": {
        "id": "CbVHYpv7HWeA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 0: Adding the API key\n",
        "Let's add the OpenAI API key to our \"secret keys\" in the Colab environment, under the name \"openai_api\". We'll do this manually."
      ],
      "metadata": {
        "id": "5RjwESDN4EAb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 1: Set up our API specification for OpenAI"
      ],
      "metadata": {
        "id": "Gx1YqhxI4TRK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cumHGBmW1Bqd"
      },
      "outputs": [],
      "source": [
        "# we will import the google.colab module so we can access the secret key we just saved\n",
        "from google.colab import userdata\n",
        "# we will use OpenAI's openai module as a client through which to use the API\n",
        "from openai import OpenAI\n",
        "\n",
        "# initialise openAI client with secret API key\n",
        "openai_client = OpenAI(\n",
        "    api_key = userdata.get('openai_api')\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GB: ToDo. Make sure to find out how to alter this for other APIs."
      ],
      "metadata": {
        "id": "wwFdA1jtXpTG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 2: Let's go through the anatomy of API calling.\n",
        "Recall that when we call an API we are basically making a request to a service, like the way we make a request to a waiter in a restaurant. And just like at a restaurant, where our waiter might expect a certain structure to how we communicate with them (e.g., specifying a main dish we want), APIs in general are exactly the same. They take certain _arguments_, which vary depending on the service, and which inform the service of how exactly to respond (e.g., which model to use). The arguments we can look at today are:\n",
        "\n",
        "*   **Model**: a string which specifies which of the models available should be used to answer the query (e.g., 4o-mini, o3, etc).\n",
        "*   **Messages**: a dictionary (i.e., with key-value pairs) which specifies the role that a message is being given as (i.e., as a system prompt vs. a user prompt) and the content of that message (e.g., what the user prompt actually says).\n",
        "* **Temperature**: a number which specifies the \"randomness\" in sampling over the tokens; a higher temperature means that less probable tokens will be selected more frequently.\n",
        "* **top_p**: a number which specifies the minimum probability that should be considered for sampling. If top_p = .1, for example, then only those tokens with a greater than 10% probability will be sampled.\n",
        "* **top_k**: a number which specifies how many of the most probable tokens should be sampled over. If top_k = 5, for example, then only the 5 most probable tokens will be considered during sampling. **Note:** Sadly, OpenAI does not expose the top_k parameter, so we can't change it. :-(\n",
        "\n"
      ],
      "metadata": {
        "id": "HPpPWAgNGszC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Specify prompts\n",
        "Let's specify our system and user prompts below. We'll start with some very basic strings."
      ],
      "metadata": {
        "id": "IYokHZFDJWVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"You are a helpful assistant and explain everything you do very informative for beginners.\"\n",
        "user_prompt = \"Give me a python code that explains how the outputs of LLMs changes with temparature and top_p.\""
      ],
      "metadata": {
        "id": "ZKaYSFkuJVo6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Call the API\n",
        "Let's talk to ChatGPT!"
      ],
      "metadata": {
        "id": "xoPKb3TjJnjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the API call\n",
        "response = openai_client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "output_text = response.choices[0].message.content # take the output and extract the text response only\n",
        "\n",
        "print(output_text) # print the output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOmnnUhUG-0u",
        "outputId": "561b6974-a107-4443-8096-c6e26d350c13",
        "collapsed": true
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Certainly! In the context of Language Models (LLMs), temperature and top_p (also known as nucleus sampling) are two important parameters that influence the randomness and diversity of the generated outputs. Let's break down what they do:\n",
            "\n",
            "1. **Temperature**: \n",
            "   - The temperature parameter controls the randomness of predictions by scaling the logits before applying the softmax function. A lower temperature (e.g., 0.1) results in more deterministic outputs, as it favors higher-probability tokens. A higher temperature (e.g., 1.0 or above) results in more random outputs, as it allows for more exploration of the probability distribution.\n",
            "\n",
            "2. **Top_p (Nucleus Sampling)**:\n",
            "   - Top_p sampling considers only the most probable tokens whose cumulative probability exceeds the threshold p. For example, if p=0.9, the model will sample from the smallest set of tokens whose total probability is at least 90%. This method allows for greater diversity in generated text while still ensuring that more likely options are preferred.\n",
            "\n",
            "### Python Code Example\n",
            "\n",
            "Below is a simple Python code example that illustrates how to generate outputs of a language model with different temperature and top_p settings. For this example, we'll make use of the Hugging Face Transformers library, which provides access to pre-trained LLMs.\n",
            "\n",
            "First, you need to install the `transformers` library if you haven't already:\n",
            "\n",
            "```bash\n",
            "pip install transformers torch\n",
            "```\n",
            "\n",
            "Now, hereâ€™s the Python code:\n",
            "\n",
            "```python\n",
            "import torch\n",
            "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
            "\n",
            "# Load the pre-trained model and tokenizer\n",
            "model_name = \"gpt2\"  # or \"gpt2-medium\", \"gpt2-large\", etc.\n",
            "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
            "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
            "model.eval()  # Put the model in evaluation mode\n",
            "\n",
            "def generate_text(prompt, temperature=1.0, top_p=1.0, max_length=50):\n",
            "    # Tokenize input prompt\n",
            "    inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
            "\n",
            "    # Generate text\n",
            "    outputs = model.generate(\n",
            "        inputs,\n",
            "        max_length=max_length,\n",
            "        do_sample=True,\n",
            "        temperature=temperature,\n",
            "        top_p=top_p\n",
            "    )\n",
            "\n",
            "    # Decode the generated output\n",
            "    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
            "    return text\n",
            "\n",
            "# Define the prompt\n",
            "prompt = \"Once upon a time in a land far, far away\"\n",
            "\n",
            "# Generate text with different temperature and top_p values\n",
            "temperature_values = [0.2, 0.7, 1.0]\n",
            "top_p_values = [0.9, 0.95, 1.0]\n",
            "\n",
            "print(\"Exploring Different Temperature and Top-p Settings:\\n\")\n",
            "\n",
            "for temperature in temperature_values:\n",
            "    for top_p in top_p_values:\n",
            "        generated_text = generate_text(prompt, temperature=temperature, top_p=top_p)\n",
            "        print(f\"Temperature: {temperature}, Top-p: {top_p}\")\n",
            "        print(generated_text)\n",
            "        print(\"-\" * 80)\n",
            "```\n",
            "\n",
            "### Explanation:\n",
            "\n",
            "1. **Importing Libraries**: The code starts by importing necessary libraries, specifically `torch` for tensor operations and `transformers` for the model and tokenizer.\n",
            "\n",
            "2. **Loading the Model and Tokenizer**: A pre-trained GPT-2 model and its tokenizer are loaded from Hugging Faceâ€™s model hub.\n",
            "\n",
            "3. **Function for Generation**:\n",
            "   - `generate_text` function takes a prompt, temperature, top_p, and max_length as inputs.\n",
            "   - It tokenizes the input prompt and uses the model to generate text based on the specified parameters.\n",
            "   - The output is then decoded back to a string for readability.\n",
            "\n",
            "4. **Defining a Prompt**: A simple prompt is defined for the text generation.\n",
            "\n",
            "5. **Generating Outputs with Loop**: The code generates texts for combinations of temperatures and top_p values provided in the lists. It outputs the results for each configuration.\n",
            "\n",
            "### How to Run the Code:\n",
            "1. Save the code into a Python file, e.g., `generate_llm_outputs.py`.\n",
            "2. Run the file using Python: `python generate_llm_outputs.py`.\n",
            "3. Observe how the outputs vary by adjusting the values of `temperature` and `top_p`.\n",
            "\n",
            "### Note:\n",
            "Depending on your machine configuration, generating text may take time, especially if you are working with a large model and using a CPU instead of a GPU.\n",
            "\n",
            "Let me know if you have any questions or need further clarification!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GB: Sytem and user prompt are kinda interchangeable. It's just text."
      ],
      "metadata": {
        "id": "NGWdg8HrbEsp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hands-on:\n",
        "Now try the following things:\n",
        "\n",
        "\n",
        "1.   Change the user prompt and re-run the request.\n",
        "2.   Change the system prompt to something completely random and re-run the request.\n",
        "\n"
      ],
      "metadata": {
        "id": "qJJccQhEJ81v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "application:"
      ],
      "metadata": {
        "id": "b4yIHMvUbZ8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"You are a helpful assistant and explain everything you do very informative for beginners.\"\n",
        "user_prompt = \"Give me a code that explains how the outputs of LLMs changes with temparature and top_p.\""
      ],
      "metadata": {
        "id": "UYIu5NOfbXeF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the API call\n",
        "response = openai_client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ],\n",
        "    temperature = 1.6,\n",
        "    top_p= .01\n",
        "    )\n",
        "\n",
        "output_text = response.choices[0].message.content # take the output and extract the text response only\n",
        "\n",
        "print(output_text) # print the output"
      ],
      "metadata": {
        "collapsed": true,
        "id": "P_8TCh3TbcJS",
        "outputId": "6601e2cb-f8ba-43eb-f0c3-3b70a079a169",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Certainly! In the context of language models, \"temperature\" and \"top-p\" (also known as nucleus sampling) are two parameters that influence the randomness and creativity of the generated text. Let's break down what each of these parameters does:\n",
            "\n",
            "1. **Temperature**: This parameter controls the randomness of predictions by scaling the logits (the raw output scores from the model before applying softmax). A lower temperature (e.g., 0.2) makes the model more confident and deterministic, often leading to more repetitive and conservative outputs. A higher temperature (e.g., 1.0 or above) increases randomness, allowing for more diverse and creative outputs.\n",
            "\n",
            "2. **Top-p (Nucleus Sampling)**: This parameter determines the cumulative probability threshold for selecting the next word. Instead of considering all possible words, the model only considers the smallest set of words whose cumulative probability exceeds the threshold `p`. For example, if `p=0.9`, the model will only consider the top words that together have a cumulative probability of 90%. This allows for more controlled randomness compared to sampling from the entire vocabulary.\n",
            "\n",
            "### Example Code\n",
            "\n",
            "Below is a Python code snippet that simulates how the outputs of a language model might change with different values of temperature and top-p. For this example, we'll use a simple mock function to represent the language model's output, as we don't have access to an actual LLM in this environment.\n",
            "\n",
            "```python\n",
            "import numpy as np\n",
            "\n",
            "def mock_language_model(prompt, temperature=1.0, top_p=1.0):\n",
            "    # Mock probabilities for the next word (for demonstration purposes)\n",
            "    vocab = [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
            "    logits = np.array([1.0, 0.5, 0.2, 0.1, 0.5, 0.3])  # Example logits for each word\n",
            "\n",
            "    # Apply temperature\n",
            "    scaled_logits = logits / temperature\n",
            "    probabilities = np.exp(scaled_logits) / np.sum(np.exp(scaled_logits))  # Softmax\n",
            "\n",
            "    # Apply top-p sampling\n",
            "    sorted_indices = np.argsort(probabilities)[::-1]\n",
            "    cumulative_probs = np.cumsum(probabilities[sorted_indices])\n",
            "    cutoff_index = np.where(cumulative_probs > top_p)[0][0]\n",
            "    filtered_indices = sorted_indices[:cutoff_index + 1]\n",
            "\n",
            "    # Sample from the filtered probabilities\n",
            "    filtered_probs = probabilities[filtered_indices]\n",
            "    filtered_probs /= np.sum(filtered_probs)  # Normalize\n",
            "\n",
            "    # Sample a word based on the filtered probabilities\n",
            "    chosen_index = np.random.choice(filtered_indices, p=filtered_probs)\n",
            "    return vocab[chosen_index]\n",
            "\n",
            "# Test the function with different temperature and top-p values\n",
            "prompt = \"The cat\"\n",
            "for temperature in [0.2, 0.5, 1.0, 1.5]:\n",
            "    for top_p in [0.5, 0.9, 1.0]:\n",
            "        output = mock_language_model(prompt, temperature, top_p)\n",
            "        print(f\"Temperature: {temperature}, Top-p: {top_p} => Output: '{output}'\")\n",
            "```\n",
            "\n",
            "### Explanation of the Code:\n",
            "\n",
            "1. **Mock Language Model**: The function `mock_language_model` simulates the behavior of a language model. It takes a prompt, temperature, and top-p as inputs.\n",
            "\n",
            "2. **Logits**: We define a set of mock logits representing the model's confidence in each word in the vocabulary.\n",
            "\n",
            "3. **Temperature Scaling**: The logits are scaled by the temperature parameter. A lower temperature results in higher confidence scores for the most likely words.\n",
            "\n",
            "4. **Softmax**: We apply the softmax function to convert the scaled logits into probabilities.\n",
            "\n",
            "5. **Top-p Sampling**: We sort the probabilities and calculate cumulative probabilities. We then filter the vocabulary to only include words that contribute to the cumulative probability up to the specified `top_p`.\n",
            "\n",
            "6. **Sampling**: Finally, we sample a word from the filtered probabilities and return it.\n",
            "\n",
            "7. **Testing**: We loop through different combinations of temperature and top-p values, calling the `mock_language_model` function and printing the outputs.\n",
            "\n",
            "### Note:\n",
            "This code is a simplified representation and does not use an actual language model. In practice, you would use a library like Hugging Face's Transformers to work with real LLMs, where you can set these parameters directly when generating text.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Temperature and top-p\n",
        "Let's go through each of these arguments one-by-one. Below you will see API calling code for the LLM with a slightly more complex prompt. Try out requests to this LLM where you:\n",
        "\n",
        "\n",
        "1.   Vary the temperature parameter.\n",
        "2. Vary the top-p parameter.\n",
        "\n",
        "Your task is try to get the funniest and weirdest response possible from the model.\n",
        "\n",
        "In order to prevent too excessive an output (and to protect our OpenAI budget!) we'll limit the output to a maximum of 50 tokens using the `max_tokens` argument; please do not change this.\n",
        "\n"
      ],
      "metadata": {
        "id": "-8kma-0mMKY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "longer_system_prompt = \"You are an expert reviewer of written text. You take a short story as an input and provide a short, expressive review of it as output, up to 50 tokens.\"\n",
        "longer_user_prompt = \"Here's my short story: Every night, the statues in the park shifted an inch east. No one noticedâ€”except Mira, the blind woman who fed pigeons by the fountain. She claimed they whispered as they moved: stories of the future etched in stone. One dawn, she wasnâ€™t there. In her place stood a new statue, arm outstretched, feeding invisible birds. The others had turned west. Since then, the cityâ€™s clocks ran backward, and no one aged. Only children still remember time.\""
      ],
      "metadata": {
        "id": "hj_giHCoMpmg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the API call\n",
        "response = openai_client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature = 1,\n",
        "    max_tokens = 50,\n",
        "    top_p = 1,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": longer_system_prompt},\n",
        "        {\"role\": \"user\", \"content\": longer_user_prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "output_text = response.choices[0].message.content # take the output and extract the text response only\n",
        "\n",
        "print(output_text) # print the output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpF_yL2hMKAW",
        "outputId": "f78be4e3-b410-4c29-e174-9f1df26b9c09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A hauntingly poetic tale blending magic and melancholy, where the ordinary twists into the extraordinary. Miraâ€™s unique perspective offers profound insights into time and memory. A captivating exploration of loss and the unseen. Beautifully imagined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 2: Let's query an academic paper\n",
        "90% of large language model workflows with an API happen _before_ we get to using the LLM. What is critically important here is that the pdf is parsed correctly, and in a manageable format, so that we can feed it efficiently to the LLM. Remember: the only type of input an LLM can take is text, so we need to convert our pdf file to text.\n",
        "Fortunately, there is an excellent machine learning service called GROBID which is made specifically for parsing academic paper pdfs! We can communicate with GROBID's API using the `requests` library. So let's try that out now: first we can define a function to do this:"
      ],
      "metadata": {
        "id": "mtSJ4is16Z-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# First, let's define a function, called read_with_grobid, which we can use to read in the pdf.\n",
        "def read_with_grobid(filename):\n",
        "\n",
        "  # specify the file, then send to GROBID\n",
        "  with open(filename, 'rb') as file:\n",
        "    files = {'input': file}\n",
        "    response = requests.post(\"https://kermitt2-grobid.hf.space/api/processFulltextDocument\", files=files) # send to grobid at the specified URL\n",
        "\n",
        "    # if the response returned from GROBID isn't 200 (indicating a successful request), then inform us of the error\n",
        "    if response.status_code != 200:\n",
        "      response.raise_for_status()\n",
        "\n",
        "  return response.text"
      ],
      "metadata": {
        "id": "h_0jIBH66yd-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's try to run the function to open our pdf!"
      ],
      "metadata": {
        "id": "A4m0JBtDBPON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paper = read_with_grobid('/content/science.aac4716.pdf')"
      ],
      "metadata": {
        "id": "39KkL0hoBOI6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(paper)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuhrB_dkCtjz",
        "outputId": "d90fdbf3-da9b-4c7a-9e0a-55c8d9e1daad",
        "collapsed": true
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
            "<TEI xml:space=\"preserve\" xmlns=\"http://www.tei-c.org/ns/1.0\" \n",
            "xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n",
            "xsi:schemaLocation=\"http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd\"\n",
            " xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
            "\t<teiHeader xml:lang=\"en\">\n",
            "\t\t<fileDesc>\n",
            "\t\t\t<titleStmt>\n",
            "\t\t\t\t<title level=\"a\" type=\"main\">Estimating the reproducibility of psychological science Open Science Collaboration*</title>\n",
            "\t\t\t\t<funder ref=\"#_aUgyjYH\">\n",
            "\t\t\t\t\t<orgName type=\"full\">unknown</orgName>\n",
            "\t\t\t\t</funder>\n",
            "\t\t\t</titleStmt>\n",
            "\t\t\t<publicationStmt>\n",
            "\t\t\t\t<publisher/>\n",
            "\t\t\t\t<availability status=\"unknown\"><licence/></availability>\n",
            "\t\t\t</publicationStmt>\n",
            "\t\t\t<sourceDesc>\n",
            "\t\t\t\t<biblStruct>\n",
            "\t\t\t\t\t<analytic>\n",
            "\t\t\t\t\t\t<title level=\"a\" type=\"main\">Estimating the reproducibility of psychological science Open Science Collaboration*</title>\n",
            "\t\t\t\t\t</analytic>\n",
            "\t\t\t\t\t<monogr>\n",
            "\t\t\t\t\t\t<imprint>\n",
            "\t\t\t\t\t\t\t<date/>\n",
            "\t\t\t\t\t\t</imprint>\n",
            "\t\t\t\t\t</monogr>\n",
            "\t\t\t\t\t<idno type=\"MD5\">D5C059F6A1F36B1ED547D1E42808ED90</idno>\n",
            "\t\t\t\t\t<idno type=\"DOI\">10.1126/science.aac4716</idno>\n",
            "\t\t\t\t</biblStruct>\n",
            "\t\t\t</sourceDesc>\n",
            "\t\t</fileDesc>\n",
            "\t\t<encodingDesc>\n",
            "\t\t\t<appInfo>\n",
            "\t\t\t\t<application version=\"0.8.1\" ident=\"GROBID\" when=\"2025-05-16T09:39+0000\">\n",
            "\t\t\t\t\t<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>\n",
            "\t\t\t\t\t<ref target=\"https://github.com/kermitt2/grobid\"/>\n",
            "\t\t\t\t</application>\n",
            "\t\t\t</appInfo>\n",
            "\t\t</encodingDesc>\n",
            "\t\t<profileDesc>\n",
            "\t\t\t<abstract>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>INTRODUCTION:</head><p>Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error.</p></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>RATIONALE:</head><p>There is concern about the rate and predictors of reproducibility, but limited evidence. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a pre-RESEARCH</p></div>\n",
            "\t\t\t</abstract>\n",
            "\t\t</profileDesc>\n",
            "\t</teiHeader>\n",
            "\t<text xml:lang=\"en\">\n",
            "\t\t<body>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><p>viously observed finding and is the means of establishing reproducibility of a finding with new data. We conducted a large-scale, collaborative effort to obtain an initial estimate of the reproducibility of psychological science.</p><p>RESULTS <ref type=\"bibr\">:</ref> We conducted replications of 100 experimental and correlational studies published in three psychology journals using highpowered designs and original materials when available. There is no single standard for evaluating replication success. Here, we evaluated reproducibility using significance and P values, effect sizes, subjective assessments of replication teams, and meta-analysis of effect sizes. The mean effect size (r) of the replication effects (M r = 0.197, SD = 0.257) was half the magnitude of the mean effect size of the original effects (M r = 0.403, SD = 0.188), representing a substantial decline. Ninety-seven percent of original studies had significant results (P &lt; .05). Thirty-six percent of replications had significant results; 47% of original effect sizes were in the 95% confidence interval of the replication effect size; 39% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.</p><p>CONCLUSION: No single indicator sufficiently describes replication success, and the five indicators examined here are not the only ways to evaluate reproducibility. Nonetheless, collectively these results offer a clear conclusion: A large portion of replications produced weaker evidence for the original findings despite using materials provided by the original authors, review in advance for methodological fidelity, and high statistical power to detect the original effect sizes. Moreover, correlational evidence is consistent with the conclusion that variation in the strength of initial evidence (such as original P value) was more predictive of replication success than variation in the characteristics of the teams conducting the research (such as experience and expertise). The latter factors certainly can influence replication success, but they did not appear to do so here.</p><p>Reproducibility is not well understood because the incentives for individual scientists prioritize novelty over replication. Innovation is the engine of discovery and is vital for a productive, effective scientific enterprise. However, innovative ideas become old news fast. Journal reviewers and editors may dismiss a new test of a published idea as unoriginal. The claim that \"we already know this\" belies the uncertainty of scientific evidence. Innovation points out paths that are possible; replication points out paths that are likely; progress relies on both. Replication can increase certainty when findings are reproduced and promote innovation when they are not. This project provides accumulating evidence for many findings in psychological research and suggests that there is still more work to do to verify whether we know what we think we know. â–ª</p><note type=\"other\">RESEARCH ARTICLE â—¥ PSYCHOLOGY</note></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Estimating the reproducibility of psychological science</head><p>Open Science Collaboration* â€  Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47% of original effect sizes were in the 95% confidence interval of the replication effect size; 39% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.</p></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>R</head><p>eproducibility is a core principle of scientific progress <ref type=\"bibr\" target=\"#b0\">(1)</ref><ref type=\"bibr\" target=\"#b1\">(2)</ref><ref type=\"bibr\" target=\"#b2\">(3)</ref><ref type=\"bibr\" target=\"#b3\">(4)</ref><ref type=\"bibr\" target=\"#b4\">(5)</ref><ref type=\"bibr\" target=\"#b5\">(6)</ref>. Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Scientists attempt to transparently describe the methodology and resulting evidence used to support their claims. Other scientists agree or disagree whether the evidence supports the claims, citing theoretical or methodological reasons or by collecting new evidence. Such debates are meaningless, however, if the evidence being debated is not reproducible.</p><p>Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a previously observed finding <ref type=\"bibr\" target=\"#b6\">(7,</ref><ref type=\"bibr\" target=\"#b7\">8)</ref> and is the means of establishing reproducibility of a finding with new data. A direct replication may not obtain the original result for a variety of reasons: Known or unknown differences between the replication and original study may moderate the size of an observed effect, the original result could have been a false positive, or the replication could produce a false negative. False positives and false negatives provide misleading information about effects, and failure to identify the necessary and sufficient conditions to reproduce a finding indicates an incomplete theoretical understanding. Direct replication provides the opportunity to assess and improve reproducibility.</p><p>There is plenty of concern (9-13) about the rate and predictors of reproducibility but limited evidence. In a theoretical analysis, Ioannidis estimated that publishing and analytic practices make it likely that more than half of research results are false and therefore irreproducible <ref type=\"bibr\" target=\"#b8\">(9)</ref>. Some empirical evidence supports this analysis. In cell biology, two industrial laboratories reported success replicating the original results of landmark findings in only 11 and 25% of the attempted cases, respectively <ref type=\"bibr\" target=\"#b9\">(10,</ref><ref type=\"bibr\" target=\"#b10\">11)</ref>. These numbers are stunning but also difficult to interpret because no details are available about the studies, methodology, or results. With no transparency, the reasons for low reproducibility cannot be evaluated.</p><p>Other investigations point to practices and incentives that may inflate the likelihood of obtaining false-positive results in particular or irreproducible results more generally. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results <ref type=\"bibr\" target=\"#b11\">(12)</ref><ref type=\"bibr\" target=\"#b12\">(13)</ref><ref type=\"bibr\" target=\"#b13\">(14)</ref><ref type=\"bibr\" target=\"#b14\">(15)</ref><ref type=\"bibr\" target=\"#b15\">(16)</ref><ref type=\"bibr\" target=\"#b16\">(17)</ref><ref type=\"bibr\" target=\"#b17\">(18)</ref><ref type=\"bibr\" target=\"#b18\">(19)</ref><ref type=\"bibr\" target=\"#b19\">(20)</ref><ref type=\"bibr\" target=\"#b20\">(21)</ref><ref type=\"bibr\" target=\"#b21\">(22)</ref><ref type=\"bibr\" target=\"#b22\">(23)</ref>. We were inspired to address the gap in direct empirical evidence about reproducibility. In this Research Article, we report a large-scale, collaborative effort to obtain an initial estimate of the reproducibility of psychological science.</p></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Method</head><p>Starting in November 2011, we constructed a protocol for selecting and conducting highquality replications <ref type=\"bibr\" target=\"#b23\">(24)</ref>. Collaborators joined the project, selected a study for replication from the available studies in the sampling frame, and were guided through the replication protocol. The replication protocol articulated the process of selecting the study and key effect from the available articles, contacting the original authors for study materials, preparing a study protocol and analysis plan, obtaining review of the protocol by the original authors and other members within the present project, registering the protocol publicly, conducting the replication, writing the final report, and auditing the process and analysis for quality control. Project coordinators facilitated each step of the process and maintained the protocol and project resources. Replication materials and data were required to be archived publicly in order to maximize transparency, accountability, and reproducibility of the project (<ref type=\"url\" target=\"https://osf.io/ezcuj\">https://osf.io/ezcuj</ref>).</p><p>In total, 100 replications were completed by 270 contributing authors. There were many different research designs and analysis strategies in the original research. Through consultation with original authors, obtaining original materials, and internal review, replications maintained high fidelity to the original designs. Analyses converted results to a common effect size metric [correlation coefficient (r)] with confidence intervals (CIs). The units of analysis for inferences about reproducibility were the original and replication study effect sizes. The resulting open data set provides an initial estimate of the reproducibility of psychology and correlational data to support development of hypotheses about the causes of reproducibility.</p></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Sampling frame and study selection</head><p>We constructed a sampling frame and selection process to minimize selection biases and maximize generalizability of the accumulated evidence. Simultaneously, to maintain high quality, within this sampling frame we matched individual replication projects with teams that had relevant interests and expertise. We pursued a quasi-random sample by defining the sampling frame as 2008 articles of three important psychology journals: Psychological Science (PSCI), Journal of Personality and Social Psychology (JPSP), and Journal of Experimental Psychology: Learning, Memory, and Cognition (JEP: LMC). The first is a premier outlet for all psychological research; the second and third are leading disciplinary-specific journals for social psychology and cognitive psychology, respectively [more information is available in <ref type=\"bibr\" target=\"#b23\">(24)</ref>]. These were selected a priori in order to (i) provide a tractable sampling frame that would not plausibly bias reproducibility estimates, (ii) enable comparisons across journal types and subdisciplines, (iii) fit with the range of expertise available in the initial collaborative team, (iv) be recent enough to obtain original materials, (v) be old enough to obtain meaningful indicators of citation impact, and (vi) represent psychology subdisciplines that have a high frequency of studies that are feasible to conduct at relatively low cost.</p><p>The first replication teams could select from a pool of the first 20 articles from each journal, starting with the first article published in the first 2008 issue. Project coordinators facilitated matching articles with replication teams by interests and expertise until the remaining articles were difficult to match. If there were still interested teams, then another 10 articles from one or more of the three journals were made available from the sampling frame. Further, project coordinators actively recruited teams from the community with relevant experience for particular articles. This approach balanced competing goals: minimizing selection bias by having only a small set of articles available at a time and matching studies with replication teams' interests, resources, and expertise.</p><p>By default, the last experiment reported in each article was the subject of replication. This decision established an objective standard for study selection within an article and was based on the intuition that the first study in a multiplestudy article (the obvious alternative selection strategy) was more frequently a preliminary demonstration. Deviations from selecting the last experiment were made occasionally on the basis of feasibility or recommendations of the original authors. Justifications for deviations were reported in the replication reports, which were made available on the Open Science Framework (OSF) (<ref type=\"url\" target=\"http://osf.io/ezcuj\">http://osf.io/ezcuj</ref>). In total, 84 of the 100 completed replications (84%) were of the last reported study in the article. On average, the to-be-replicated articles contained 2.99 studies (SD = 1.78) with the following distribution: 24 single study, 24 two studies, 18 three studies, 13 four studies, 12 five studies, 9 six or more studies. All following summary statistics refer to the 100 completed replications.</p><p>For the purposes of aggregating results across studies to estimate reproducibility, a key result from the selected experiment was identified as the focus of replication. The key result had to be represented as a single statistical inference test or an effect size. In most cases, that test was a t test, F test, or correlation coefficient. This effect was identified before data collection or analysis and was presented to the original authors as part of the design protocol for critique. Original authors occasionally suggested that a different effect be used, and by default, replication teams deferred to original authors' judgments. Nonetheless, because the single effect came from a single study, it is not necessarily the case that the identified effect was central to the overall aims of the article. In the individual replication reports and subjective assessments of replication outcomes, more than a single result could be examined, but only the result of the single effect was considered in the aggregate analyses [additional details of the general protocol and individual study methods are provided in the supplementary materials and ( <ref type=\"formula\">25</ref>)].</p><p>In total, there were 488 articles in the 2008 issues of the three journals. One hundred fiftyeight of these (32%) became eligible for selection for replication during the project period, between November 2011 and December 2014. From those, 111 articles (70%) were selected by a replication team, producing 113 replications. Two articles had two replications each (supplementary materials). And 100 of those (88%) replications were completed by the project deadline for inclusion in this aggregate report. After being claimed, some studies were not completed because the replication teams ran out of time or could not devote sufficient resources to completing the study. By journal, replications were completed for 39 of 64 (61%) articles from PSCI, 31 of 55 (56%) articles from JPSP, and 28 of 39 (72%) articles from JEP:LMC.</p><p>The most common reasons for failure to match an article with a team were feasibility constraints for conducting the research. Of the 47 articles from the eligible pool that were not claimed, six (13%) had been deemed infeasible to replicate because of time, resources, instrumentation, dependence on historical events, or hard-to-access samples. The remaining 41 (87%) were eligible but not claimed. These often required specialized samples (such as macaques or people with autism), resources (such as eye tracking machines or functional magnetic resonance imaging), or knowledge making them difficult to match with teams.</p></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Aggregate data preparation</head><p>Each replication team conducted the study, analyzed their data, wrote their summary report, and completed a checklist of requirements for sharing the materials and data. Then, independent reviewers and analysts conducted a projectwide audit of all individual projects, materials, data, and reports. A description of this review is available on the OSF (<ref type=\"url\" target=\"https://osf.io/xtine\">https://osf.io/xtine</ref>). Moreover, to maximize reproducibility and accuracy, the analyses for every replication study were reproduced by another analyst independent of the replication team using the R statistical programming language and a standardized analytic format. A controller R script was created to regenerate the entire analysis of every study and recreate the master data file. This R script, available at <ref type=\"url\" target=\"https://osf.io/fkmwg\">https://osf.io/fkmwg</ref>, can be executed to reproduce the results of the individual studies. A comprehensive description of this reanalysis process is available publicly (<ref type=\"url\" target=\"https://osf.io/a2eyg\">https://osf.io/a2eyg</ref>).</p></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Measures and moderators</head><p>We assessed features of the original study and replication as possible correlates of reproducibility and conducted exploratory analyses to inspire further investigation. These included characteristics of the original study such as the publishing journal; original effect size, P value, and sample size; experience and expertise of the original research team; importance of the effect, with indicators such as the citation impact of the article; and rated surprisingness of the effect. We also assessed characteristics of the replication such as statistical power and sample size, experience and expertise of the replication team, independently assessed challenge of conducting an effective replication, and self-assessed quality of the replication effort. Variables such as the P value indicate the statistical strength of evidence given the null hypothesis, and variables such as \"effect surprisingness\" and \"expertise of the team\" indicate qualities of the topic of study and the teams studying it, respectively. The master data file, containing these and other variables, is available for exploratory analysis (<ref type=\"url\" target=\"https://osf.io/5wup8\">https://osf.io/5wup8</ref>).</p><p>It is possible to derive a variety of hypotheses about predictors of reproducibility. To reduce the likelihood of false positives due to many tests, we aggregated some variables into summary indicators: experience and expertise of original team, experience and expertise of replication team, challenge of replication, self-assessed quality of repli-cation, and importance of the effect. We had no a priori justification to give some indicators stronger weighting over others, so aggregates were created by standardizing [mean (M) = 0, SD = 1] the individual variables and then averaging to create a single index. In addition to the publishing journal and subdiscipline, potential moderators included six characteristics of the original study and five characteristics of the replication (supplementary materials).</p></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Publishing journal and subdiscipline</head><p>Journals' different publishing practices may result in a selection bias that covaries with reproducibility. Articles from three journals were made available for selection: JPSP (n = 59 articles), JEP: LMC (n = 40 articles), and PSCI (n = 68 articles). From this pool of available studies, replications were selected and completed from JPSP (n = 32 studies), JEP:LMC (n = 28 studies), and PSCI (n = 40 studies) and were coded as representing cognitive (n = 43 studies) or social-personality (n = 57 studies) subdisciplines. Four studies that would ordinarily be understood as \"developmental psychology\" because of studying children or infants were coded as having a cognitive or social emphasis. Reproducibility may vary by subdiscipline in psychology because of differing practices. For example, within-subjects designs are more common in cognitive than social psychology, and these designs often have greater power to detect effects with the same number of participants.</p></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Statistical analyses</head><p>There is no single standard for evaluating replication success <ref type=\"bibr\" target=\"#b24\">(25)</ref>. We evaluated reproducibility using significance and P values, effect sizes, subjective assessments of replication teams, and meta-analyses of effect sizes. All five of these indicators contribute information about the relations between the replication and original finding and the cumulative evidence about the effect and were positively correlated with one another (r ranged from 0.22 to 0.96, median r = 0.57). Results are summarized in Table <ref type=\"table\">1</ref>, and full details of analyses are in the supplementary materials.</p></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Significance and P values</head><p>Assuming a two-tailed test and significance or a level of 0.05, all test results of original and replication studies were classified as statistically significant (P â‰¤ 0.05) and nonsignificant (P &gt; 0.05). However, original studies that interpreted nonsignificant P values as significant were coded as significant (four cases, all with P values &lt; 0.06). Using only the nonsignificant P values of the replication studies and applying Fisher's method <ref type=\"bibr\" target=\"#b25\">(26)</ref>, we tested the hypothesis that these studies had \"no evidential value\" (the null hypothesis of zero-effect holds for all these studies). We tested the hypothesis that the proportions of statistically significant results in the original and replication studies are equal using the McNemar test for paired nominal data and calculated a CI of the reproducibility parameter. Second, we compared the central tendency of the distribution of P values of original and replication studies using the Wilcoxon signedrank test and the t test for dependent samples. For both tests, we only used study-pairs for which both P values were available.</p></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Effect sizes</head><p>We transformed effect sizes into correlation coefficients whenever possible. Correlation coefficients have several advantages over other effect size measures, such as Cohen's d. Correlation coefficients are bounded, well known, and therefore more readily interpretable. Most important for our purposes, analysis of correlation coefficients is straightforward because, after ap-plying the Fisher transformation, their standard error is only a function of sample size. Formulas and code for converting test statistics z, F, t, and c 2 into correlation coefficients are provided in the appendices at <ref type=\"url\" target=\"http://osf.io/ezum7\">http://osf.io/ezum7</ref>. To be able to compare and analyze correlations across studypairs, the original study's effect size was coded as positive; the replication study's effect size was coded as negative if the replication study's effect was opposite to that of the original study.</p><p>We compared effect sizes using four tests. We compared the central tendency of the effect size distributions of original and replication studies using both a paired two-sample t test and the Wilcoxon signed-rank test. Third, we computed the proportion of study-pairs in which the effect of the original study was stronger than in the replication study and tested the hypothesis that this proportion is 0.5. For this test, we included findings for which effect size measures were available but no correlation coefficient could be computed (for example, if a regression coefficient was reported but not its test statistic). Fourth, we calculated \"coverage,\" or the proportion of study-pairs in which the effect of the original study was in the CI of the effect of the replication study, and compared this with the expected proportion using a goodness-of-fit c 2 test. We carried</p><formula xml:id=\"formula_0\">SCIENCE sciencemag.org 28 AUGUST 2015 â€¢ VOL 349 ISSUE 6251 aac4716-3</formula><p>Table <ref type=\"table\">2</ref>. Spearman's rank-order correlations of reproducibility indicators with summary original and replication study characteristics. Effect size difference computed after converting r to Fisher's z. df/N refers to the information on which the test of the effect was based (for example, df of t test, denominator df of F test, sample size -3 of correlation, and sample size for z and c 2 ). Four original results had P values slightly higher than 0.05 but were considered positive results in the original article and are treated that way here. Exclusions (explanation provided in supplementary materials, A3) are \"replications P &lt; .05\" (3 original nulls excluded; n = 97 studies), \"effect size difference\" (3 excluded; n = 97 studies); \"meta-analytic mean estimates\" (27 excluded; n = 73 studies); and, \"percent original effect size within replication 95% CI\" (5 excluded, n = 95 studies).   <ref type=\"table\">1</ref>. Summary of reproducibility rates and effect sizes for original and replication studies overall and by journal/discipline. df/N refers to the information on which the test of the effect was based (for example, df of t test, denominator df of F test, sample size -3 of correlation, and sample size for z and c 2 ). Four original results had P values slightly higher than 0.05 but were considered positive results in the original article and are treated that way here. Exclusions (explanation provided in supplementary materials, A3) are \"replications P &lt; 0.05\" (3 original nulls excluded; n = 97 studies); \"mean original and replication effect sizes\" (3 excluded; n = 97 studies); \"meta-analytic mean estimates\" (27 excluded; n = 73 studies); \"percent meta-analytic (P &lt; 0.05)\" (25 excluded; n = 75 studies); and, \"percent original effect size within replication 95% CI\" (5 excluded, n = 95 studies).  out this test on the subset of study pairs in which both the correlation coefficient and its standard error could be computed [we refer to this data set as the meta-analytic (MA) subset]. Standard errors could only be computed if test statistics were r, t, or F(1,df 2 ). The expected proportion is the sum over expected probabilities across studypairs. The test assumes the same population effect size for original and replication study in the same study-pair. For those studies that tested the effect with F(df 1 &gt; 1, df 2 ) or c 2 , we verified coverage using other statistical procedures (computational details are provided in the supplementary materials).</p></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Effect size comparison</head></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Meta-analysis combining original and replication effects</head><p>We conducted fixed-effect meta-analyses using the R package metafor ( <ref type=\"formula\">27</ref>) on Fisher-transformed correlations for all study-pairs in subset MA and on study-pairs with the odds ratio as the dependent variable. The number of times the CI of all these meta-analyses contained 0 was calculated.</p><p>For studies in the MA subset, estimated effect sizes were averaged and analyzed by discipline.</p><p>Subjective assessment of \"Did it replicate?\"</p><p>In addition to the quantitative assessments of replication and effect estimation, we collected subjective assessments of whether the replication provided evidence of replicating the original result. In some cases, the quantitative data anticipate a straightforward subjective assessment of replication. For more complex designs, such as multivariate interaction effects, the quantitative analysis may not provide a simple interpretation. For subjective assessment, replication teams answered \"yes\" or \"no\" to the question, \"Did your results replicate the original effect?\" Additional subjective variables are available for analysis in the full data set.</p></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Analysis of moderators</head><p>We correlated the five indicators evaluating reproducibility with six indicators of the origi-nal study (original P value, original effect size, original sample size, importance of the effect, surprising effect, and experience and expertise of original team) and seven indicators of the replication study (replication P value, replication effect size, replication power based on original effect size, replication sample size, challenge of conducting replication, experience and expertise of replication team, and self-assessed quality of replication) (Table <ref type=\"table\">2</ref>). As follow-up, we did the same with the individual indicators comprising the moderator variables (tables S3 and S4).</p></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Results</head></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Evaluating replication effect against null hypothesis of no effect</head><p>A straightforward method for evaluating replication is to test whether the replication shows a statistically significant effect (P &lt; 0.05) with the same direction as the original study. This dichotomous vote-counting method is intuitively appealing and consistent with common heuristics used to decide whether original studies \"worked.\" Ninety-seven of 100 (97%) effects from original studies were positive results (four had P values falling a bit short of the 0.05 criterion-P = 0.0508, 0.0514, 0.0516, and 0.0567but all of these were interpreted as positive effects). On the basis of only A key weakness of this method is that it treats the 0.05 threshold as a bright-line criterion between replication success and failure <ref type=\"bibr\" target=\"#b27\">(28)</ref>. It could be that many of the replications fell just short of the 0.05 criterion. The density plots of P values for original studies (mean P value = 0.028) and replications (mean P value = 0.302) are shown in Fig. <ref type=\"figure\">1</ref>, left. The 64 nonsignificant P values for replications were distributed widely. When there is no effect to detect, the null distribution of P values is uniform. This distribution deviated slightly from uniform with positive skew, however, suggesting that at least one replication could be a false negative, c 2 (128) = 155.83, P = 0.048. Nonetheless, the wide distribution of P values suggests against insufficient power as the only explanation for failures to replicate. A scatterplot of original compared with replication study P values is shown in Fig. <ref type=\"figure\">2</ref>.</p></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Evaluating replication effect against original effect size</head><p>A complementary method for evaluating replication is to test whether the original effect size is within the 95% CI of the effect size estimate from the replication. For the subset of 73 studies in which the standard error of the correlation could be computed, 30 (41.1%) of the replication CIs contained the original effect size (significantly lower than the expected value of 78.5%, P &lt; 0.001) (supplementary materials). For 22 studies using other test statistics [F(df 1 &gt; 1, df 2 ) and c 2 ], 68.2% of CIs contained the effect size of the original study. Overall, this analysis suggests a 47.4% replication success rate.</p><p>This method addresses the weakness of the first test that a replication in the same direction and a P value of 0.06 may not be significantly different from the original result. However, the method will also indicate that a replication \"fails\" when the direction of the effect is the same but the replication effect size is significantly smaller than the original effect size <ref type=\"bibr\" target=\"#b28\">(29)</ref>. Also, the replication \"succeeds\" when the result is near zero but not estimated with sufficiently high precision to be distinguished from the original effect size.</p></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Comparing original and replication effect sizes</head><p>Comparing the magnitude of the original and replication effect sizes avoids special emphasis on P values. Overall, original study effect sizes (M = 0.403, SD = 0.188) were reliably larger than replication effect sizes (M = 0.197, SD = 0.257), Wilcoxon's W = 7137, P &lt; 0.001. Of the 99 studies for which an effect size in both the original and replication study could be calculated <ref type=\"bibr\" target=\"#b29\">(30)</ref>, 82 showed a stronger effect size in the original study (82.8%; P &lt; 0.001, binomial test) (Fig. <ref type=\"figure\">1</ref>, right). Original and replication effect sizes were positively correlated (Spearman's r = 0.51, P &lt; 0.001). A scatterplot of the original and replication effect sizes is presented in Fig. <ref type=\"figure\">3</ref>.</p></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Combining original and replication effect sizes for cumulative evidence</head><p>The disadvantage of the descriptive comparison of effect sizes is that it does not provide information about the precision of either estimate or resolution of the cumulative evidence for the effect. This is often addressed by computing a meta-analytic estimate of the effect sizes by combining the original and replication studies <ref type=\"bibr\" target=\"#b27\">(28)</ref>. This approach weights each study by the inverse of its variance and uses these weighted estimates of effect size to estimate cumulative evidence and precision of the effect. Using a fixed-effect model, 51 of the 75 (68%) effects for which a meta-analytic estimate could be computed had 95% CIs that did not include 0.</p><p>One qualification about this result is the possibility that the original studies have inflated effect sizes due to publication, selection, reporting, or other biases <ref type=\"bibr\" target=\"#b8\">(9,</ref><ref type=\"bibr\" target=\"#b11\">(12)</ref><ref type=\"bibr\" target=\"#b12\">(13)</ref><ref type=\"bibr\" target=\"#b13\">(14)</ref><ref type=\"bibr\" target=\"#b14\">(15)</ref><ref type=\"bibr\" target=\"#b15\">(16)</ref><ref type=\"bibr\" target=\"#b16\">(17)</ref><ref type=\"bibr\" target=\"#b17\">(18)</ref><ref type=\"bibr\" target=\"#b18\">(19)</ref><ref type=\"bibr\" target=\"#b19\">(20)</ref><ref type=\"bibr\" target=\"#b20\">(21)</ref><ref type=\"bibr\" target=\"#b21\">(22)</ref><ref type=\"bibr\" target=\"#b22\">(23)</ref>. In a discipline with low-powered research designs and an emphasis on positive results for publication, effect sizes will be systematically overestimated in the published literature. There is no publication bias in the replication studies because all results are reported. Also, there are no selection or reporting biases because all were confirmatory tests based on pre-analysis plans. This maximizes the interpretability of the replication P values and effect estimates. If publication, selection, and reporting biases completely explain the effect differences, then the replication estimates would be a better estimate of the effect size than would the metaanalytic and original results. However, to the extent that there are other influences, such as moderation by sample, setting, or quality of replication, the relative bias influencing original and replication effect size estimation is unknown.</p></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Subjective assessment of \"Did it replicate?\"</head><p>In addition to the quantitative assessments of replication and effect estimation, replication teams provided a subjective assessment of replication success of the study they conducted. Subjective assessments of replication success were very similar to significance testing results (39 of 100 successful replications), including evaluating \"success\" for two null replications when the original study reported a null result and \"failure\" for a P &lt; 0.05 replication when the original result was a null.</p></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Correlates of reproducibility</head><p>The overall replication evidence is summarized in Table <ref type=\"table\">1</ref> across the criteria described above and then separately by journal/discipline. Considering significance testing, reproducibility was stronger in studies and journals representing cognitive psychology than social psychology topics. For example, combining across journals, 14 of 55 (25%) of social psychology effects replicated by the P &lt; 0.05 criterion, whereas 21 of 42 (50%) of cognitive psychology effects did so. Simultaneously, all journals and disciplines showed substantial and similar [c 2 (3) = 2.45, P = 0.48] declines in effect size in the replications compared with the original studies. The difference in significance testing results between fields appears to be partly a function of weaker original effects in social psychology studies, particularly in JPSP, and perhaps of the greater frequency of high-powered within-subjects manipulations and repeated measurement designs in cognitive psychology as suggested by high power despite relatively small participant samples. Further, the type of test was associated with replication success. Among original, significant effects, 23 of the 49 (47%) that tested main or simple effects replicated at P &lt; 0.05, but just 8 of the 37 (22%) that tested interaction effects did.</p><p>Correlations between reproducibility indicators and characteristics of replication and original studies are provided in Table <ref type=\"table\">2</ref>. A negative correlation of replication success with the original study P value indicates that the initial strength of evidence is predictive of reproducibility. For example, 26 of 63 (41%) original studies with P &lt; 0.02 achieved P &lt; 0.05 in the replication, whereas 6 of 23 (26%) that had a P value between 0.02 &lt; P &lt; 0.04 and 2 of 11 (18%) that had a P value &gt; 0.04 did so (Fig. <ref type=\"figure\">2</ref>). Almost two thirds (20 of 32, 63%) of original studies with P &lt; 0.001 had a significant P value in the replication.</p><p>Larger original effect sizes were associated with greater likelihood of achieving P &lt; 0.05 (r = 0.304) and a greater effect size difference between original and replication (r = 0.279). Moreover, replication power was related to replication success via significance testing (r = 0.368) but not with the effect size difference between original and replication (r = -0.053). Comparing effect sizes across indicators, surprisingness of the original effect, and the challenge of conducting the replication were related to replication success for some indicators. Surprising effects were less reproducible, as were effects for which it was more challenging to conduct the replication. Last, there was little evidence that perceived importance of the effect, expertise of the original or replication teams, or self-assessed quality of the replication accounted for meaningful variation in reproducibility across indicators. Replication success was more consistently related to the original strength of evidence (such as original P value, effect size, and effect tested) than to characteristics of the teams and implementation of the replication (such as expertise, quality, or challenge of conducting study) (tables S3 and S4).</p></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Discussion</head><p>No single indicator sufficiently describes replication success, and the five indicators examined here are not the only ways to evaluate reproducibility. Nonetheless, collectively, these results offer a clear conclusion: A large portion of replications produced weaker evidence for the original findings (31) despite using materials provided by the original authors, review in advance for methodological fidelity, and high statistical power to detect the original effect sizes. Moreover, correlational evidence is consistent with the conclusion that variation in the strength of initial evidence (such as original P value) was more predictive of replication success than was variation in the characteristics of the teams conducting the research (such as experience and expertise). The latter factors certainly can influence replication success, but the evidence is that they did not systematically do so here. Other investigators may develop alternative indicators to explore further the role of expertise and quality in reproducibility on this open data set.</p></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Insights on reproducibility</head><p>It is too easy to conclude that successful replication means that the theoretical understanding of the original finding is correct. Direct replication mainly provides evidence for the reliability of a result. If there are alternative explanations for the original finding, those alternatives could likewise account for the replication. Understanding is achieved through multiple, diverse investigations that provide converging support for a theoretical interpretation and rule out alternative explanations.</p><p>It is also too easy to conclude that a failure to replicate a result means that the original evidence was a false positive. Replications can fail if the replication methodology differs from the original in ways that interfere with observing the effect. We conducted replications designed to minimize a priori reasons to expect a different result by using original materials, engaging original authors for review of the designs, and conducting internal reviews. Nonetheless, unanticipated factors in the sample, setting, or procedure could still have altered the observed effect magnitudes <ref type=\"bibr\" target=\"#b31\">(32)</ref>.</p><p>More generally, there are indications of cultural practices in scientific communication that may be responsible for the observed results. Lowpower research designs combined with publication bias favoring positive results together produce a literature with upwardly biased effect sizes <ref type=\"bibr\" target=\"#b13\">(14,</ref><ref type=\"bibr\" target=\"#b15\">16,</ref><ref type=\"bibr\" target=\"#b32\">33,</ref><ref type=\"bibr\" target=\"#b33\">34)</ref>. This anticipates that replication effect sizes would be smaller than original studies on a routine basis-not because of differences in implementation but because the original study effect sizes are affected by publication and reporting bias, and the replications are not. Consistent with this expectation, most replication effects were smaller than original results, and reproducibility success was correlated with indicators of the strength of initial evidence, such as lower original P values and larger effect sizes. This suggests publication, selection, and reporting biases as plausible explanations for the difference between original and replication effects. The replication studies significantly reduced these biases because replication preregistration and pre-analysis plans ensured confirmatory tests and reporting of all results.</p><p>The observed variation in replication and original results may reduce certainty about the statistical inferences from the original studies but also provides an opportunity for theoretical innovation to explain differing outcomes, and then new research to test those hypothesized explanations. The correlational evidence, for example, suggests that procedures that are more challenging to execute may result in less reproducible results, and that more surprising original effects may be less reproducible than less surprising original effects. Further, systematic, repeated replication efforts that fail to identify conditions under which the original finding can be observed reliably may reduce confidence in the original finding.</p></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Implications and limitations</head><p>The present study provides the first open, systematic evidence of reproducibility from a sample of studies in psychology. We sought to maximize generalizability of the results with a structured process for selecting studies for replication. However, it is unknown the extent to which these findings extend to the rest of psychology or other disciplines. In the sampling frame itself, not all articles were replicated; in each article, only one study was replicated; and in each study, only one statistical result was subject to replication. More resource-intensive studies were less likely to be included than were less resource-intensive studies. Although study selection bias was reduced by the sampling frame and selection strategy, the impact of selection bias is unknown.</p><p>We investigated the reproducibility rate of psychology not because there is something special about psychology, but because it is our discipline. Concerns about reproducibility are widespread across disciplines (9-21). Reproducibility is not well understood because the incentives for individual scientists prioritize novelty over replication <ref type=\"bibr\" target=\"#b19\">(20)</ref>. If nothing else, this project demonstrates that it is possible to conduct a large-scale examination of reproducibility despite the incentive barriers. Here, we conducted single-replication attempts of many effects obtaining broad-and-shallow evidence. These data provide information about reproducibility in general but little precision about individual effects in particular. A complementary narrow-and-deep approach is characterized by the Many Labs replication projects <ref type=\"bibr\" target=\"#b31\">(32)</ref>. In those, many replications of single effects allow precise estimates of effect size but result in generalizability that is circumscribed to those individual effects. Pursuing both strategies across disciplines, such as the ongoing effort in cancer biology <ref type=\"bibr\" target=\"#b34\">(35)</ref>, would yield insight about common and distinct aac4716-6 challenges and may cross-fertilize strategies so as to improve reproducibility. Because reproducibility is a hallmark of credible scientific evidence, it is tempting to think that maximum reproducibility of original results is important from the onset of a line of inquiry through its maturation. This is a mistake. If initial ideas were always correct, then there would hardly be a reason to conduct research in the first place. A healthy discipline will have many false starts as it confronts the limits of present understanding.</p><p>Innovation is the engine of discovery and is vital for a productive, effective scientific enterprise. However, innovative ideas become old news fast. Journal reviewers and editors may dismiss a new test of a published idea as unoriginal. The claim that \"we already know this\" belies the uncertainty of scientific evidence. Deciding the ideal balance of resourcing innovation versus verification is a question of research efficiency. How can we maximize the rate of research progress? Innovation points out paths that are possible; replication points out paths that are likely; progress relies on both. The ideal balance is a topic for investigation itself. Scientific incentives-funding, publication, or awards-can be tuned to encourage an optimal balance in the collective effort of discovery <ref type=\"bibr\" target=\"#b35\">(36,</ref><ref type=\"bibr\" target=\"#b36\">37)</ref>.</p><p>Progress occurs when existing expectations are violated and a surprising result spurs a new investigation. Replication can increase certainty when findings are reproduced and promote innovation when they are not. This project provides accumulating evidence for many findings in psychological research and suggests that there is still more work to do to verify whether we know what we think we know.</p></div>\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Conclusion</head><p>After this intensive effort to reproduce a sample of published psychological findings, how many of the effects have we established are true? Zero. And how many of the effects have we established are false? Zero. Is this a limitation of the project design? No. It is the reality of doing science, even if it is not appreciated in daily practice. Humans desire certainty, and science infrequently provides it. As much as we might wish it to be otherwise, a single study almost never provides definitive resolution for or against an effect and its explanation. The original studies examined here offered tentative evidence; the replications we conducted offered additional, confirmatory evidence. In some cases, the replications increase confidence in the reliability of the original results; in other cases, the replications suggest that more investigation is needed to establish the validity of the original findings. Scientific progress is a cumulative process of uncertainty reduction that can only succeed if science itself remains the greatest skeptic of its explanatory claims.</p><p>The present results suggest that there is room to improve reproducibility in psychology. Any temptation to interpret these results as a defeat for psychology, or science more generally, must contend with the fact that this project demon-strates science behaving as it should. Hypotheses abound that the present culture in science may be negatively affecting the reproducibility of findings. An ideological response would discount the arguments, discredit the sources, and proceed merrily along. The scientific process is not ideological. Science does not always provide comfort for what we wish to be; it confronts us with what is. Moreover, as illustrated by the Transparency and Openness Promotion (TOP) Guidelines (<ref type=\"url\" target=\"http://cos.io/top\">http://cos.io/top</ref>) <ref type=\"bibr\" target=\"#b36\">(37)</ref>, the research community is taking action already to improve the quality and credibility of the scientific literature.</p><p>We conducted this project because we care deeply about the health of our discipline and believe in its promise for accumulating knowledge about human behavior that can advance the quality of the human condition. Reproducibility is central to that aim. Accumulating evidence is the scientific community's method of self-correction and is the best available option for achieving that ultimate goal: truth. P. Whitehead, C. Widmann, D. K. Williams, K. M. Williams, and H. Yi. Also, we thank the authors of the original research that was the subject of replication in this project. These authors were generous with their time, materials, and advice for improving the quality of each replication and identifying the strengths and limits of the outcomes. The authors of this work are listed alphabetically. This project was supported by the Center for Open Science and the Laura and John Arnold Foundation. The authors declare no financial conflict of interest with the reported research.</p></div><figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_0\"><head></head><label></label><figDesc>Subjective \"yes\" to \"Did it replicate?\" Original study characteristics ............................................................................................................................................................................................................................................................................................................................................ ......................................................................................................................................................................................................................................................................................................................................... .........................................................................................................................................................................................................................................................................................................................................</figDesc></figure>\n",
            "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_1\"><head></head><label></label><figDesc>.........................................................................................................................................................................................................................................................................................................................................</figDesc></figure>\n",
            "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_2\"><head>aac4716- 4 Fig. 1 .</head><label>41</label><figDesc>Fig. 1. Density plots of original and replication P values and effect sizes. (A) P values. (B) Effect sizes (correlation coefficients). Lowest quantiles for P values are not visible because they are clustered near zero.</figDesc></figure>\n",
            "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_3\"><head>5 Fig. 2 .</head><label>52</label><figDesc>Fig. 2. Scatterplots of original study and replication P values for three psychology journals. Data points scaled by power of the replication based on original study effect size. Dotted red lines indicate P = 0.05 criterion. Subplot below shows P values from the range between the gray lines (P = 0 to 0.005) in the main plot above.</figDesc><graphic coords=\"6,81.92,50.12,252.06,334.89\" type=\"bitmap\" /></figure>\n",
            "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"table\" xml:id=\"tab_0\"><head></head><label></label><figDesc>........................................................................................................................................................................................................................................................................................................................................... ........................................................................................................................................................................................................................................................................................................................................... ........................................................................................................................................................................................................................................................................................................................................... ...........................................................................................................................................................................................................................................................................................................................................</figDesc><table><row><cell>Table</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Original df/N</cell><cell>-0.150</cell><cell>-0.194</cell><cell>-0.502</cell><cell>-0.221</cell><cell>-0.185</cell></row><row><cell>Importance of original result</cell><cell>-0.105</cell><cell>0.038</cell><cell>-0.205</cell><cell>-0.133</cell><cell>-0.074</cell></row><row><cell>Surprising original result</cell><cell>-0.244</cell><cell>0.102</cell><cell>-0.181</cell><cell>-0.113</cell><cell>-0.241</cell></row><row><cell>Experience and expertise of original team</cell><cell>-0.072</cell><cell>-0.033</cell><cell>-0.059</cell><cell>-0.103</cell><cell>-0.044</cell></row><row><cell>Replication P value</cell><cell>-0.828</cell><cell>0.621</cell><cell>-0.614</cell><cell>-0.562</cell><cell>-0.738</cell></row><row><cell>Replication effect size</cell><cell>0.731</cell><cell>-0.586</cell><cell>0.850</cell><cell>0.611</cell><cell>0.710</cell></row><row><cell>Replication power</cell><cell>0.368</cell><cell>-0.053</cell><cell>0.142</cell><cell>-0.056</cell><cell>0.285</cell></row><row><cell>Replication df/N</cell><cell>-0.085</cell><cell>-0.224</cell><cell>-0.692</cell><cell>-0.257</cell><cell>-0.164</cell></row><row><cell>Challenge of conducting replication</cell><cell>-0.219</cell><cell>0.085</cell><cell>-0.301</cell><cell>-0.109</cell><cell>-0.151</cell></row><row><cell>Experience and expertise of replication team</cell><cell>-0.096</cell><cell>0.133</cell><cell>0.017</cell><cell>-0.053</cell><cell>-0.068</cell></row><row><cell>Self-assessed quality of replication</cell><cell>-0.069</cell><cell>0.017</cell><cell>0.054</cell><cell>-0.088</cell><cell>-0.055</cell></row></table><note><p>............................................................................................................................................................................................................................................................................................................................................ ............................................................................................................................................................................................................................................................................................................................................ ............................................................................................................................................................................................................................................................................................................................................ ............................................................................................................................................................................................................................................................................................................................................ Replication characteristics ............................................................................................................................................................................................................................................................................................................................................ ............................................................................................................................................................................................................................................................................................................................................ ................................................................................................................................................................................................................................................................................................................................................ ............................................................................................................................................................................................................................................................................................................................................</p></note></figure>\n",
            "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"table\" xml:id=\"tab_1\"><head></head><label></label><figDesc>........................................................................................................................................................................................................................................................................................................................................... ........................................................................................................................................................................................................................................................................................................................................... ...........................................................................................................................................................................................................................................................................................................................................</figDesc><table><row><cell>Overall</cell><cell>35/97</cell><cell cols=\"4\">36 0.403 (0.188) 54 0.197 (0.257)</cell><cell>68</cell><cell>0.92</cell><cell>0.309 (0.223)</cell><cell>68</cell><cell>47</cell><cell>39</cell></row><row><cell>JPSP, social</cell><cell>7/31</cell><cell>23</cell><cell>0.29 (0.10)</cell><cell>73</cell><cell>0.07 (0.11)</cell><cell>120</cell><cell>0.91</cell><cell>0.138 (0.087)</cell><cell>43</cell><cell>34</cell><cell>25</cell></row><row><cell>JEP:LMC, cognitive</cell><cell>13/27</cell><cell>48</cell><cell>0.47 (0.18)</cell><cell cols=\"2\">36.5 0.27 (0.24)</cell><cell>43</cell><cell>0.93</cell><cell>0.393 (0.209)</cell><cell>86</cell><cell>62</cell><cell>54</cell></row><row><cell>PSCI, social</cell><cell>7/24</cell><cell>29</cell><cell>0.39 (0.20)</cell><cell>76</cell><cell>0.21 (0.30)</cell><cell>122</cell><cell>0.92</cell><cell>0.286 (0.228)</cell><cell>58</cell><cell>40</cell><cell>32</cell></row><row><cell>PSCI, cognitive</cell><cell>8/15</cell><cell>53</cell><cell>0.53 (0.2)</cell><cell>23</cell><cell>0.29 (0.35)</cell><cell>21</cell><cell>0.94</cell><cell>0.464 (0.221)</cell><cell>92</cell><cell>60</cell><cell>53</cell></row></table><note><p>...............................................................................................................................................................................................................................................................................................................................................</p></note></figure>\n",
            "<figure xmlns=\"http://www.tei-c.org/ns/1.0\" type=\"table\" xml:id=\"tab_3\"><head></head><label></label><figDesc>Fig.3. Original study effect size versus replication effect size (correlation coefficients). Diagonal line represents replication effect size equal to original effect size. Dotted line represents replication effect size of 0. Points below the dotted line were effects in the opposite direction of the original. Density plots are separated by significant (blue) and nonsignificant (red) effects.RESEARCH | RESEARCH ARTICLEDownloaded from https://www.science.org at Universitaetsbibliothek Bern onMay 11, 2025    </figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Not Significant</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Significant</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Replication Power</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.6</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.7</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.8</cell></row><row><cell></cell><cell>1.00</cell><cell></cell><cell></cell><cell></cell><cell>0.9</cell></row><row><cell></cell><cell>0.75</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Replication Effect Size</cell><cell>0.00 0.25 0.50</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>-0.25</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>-0.50</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.00</cell><cell>0.25</cell><cell>0.50</cell><cell>0.75</cell><cell>1.00</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Original Effect Size</cell><cell></cell></row></table><note><p>28 AUGUST 2015 â€¢ VOL 349 ISSUE 6251 sciencemag.org SCIENCE p-value</p></note></figure>\n",
            "\t\t\t<note xmlns=\"http://www.tei-c.org/ns/1.0\" place=\"foot\" n=\"28\" xml:id=\"foot_0\"><p>AUGUST 2015 â€¢ VOL 349 ISSUE 6251 aac4716-1*All authors with their affiliations appear at the end of this paper. â€ Corresponding author. E-mail: nosek@virginia.edu Downloaded from https://www.science.org at Universitaetsbibliothek Bern onMay 11, 2025   </p></note>\n",
            "\t\t\t<note xmlns=\"http://www.tei-c.org/ns/1.0\" place=\"foot\" xml:id=\"foot_1\"><p>aac4716-2 28 AUGUST 2015 â€¢ VOL 349 ISSUE 6251 sciencemag.org SCIENCE RESEARCH | RESEARCH ARTICLE Downloaded from https://www.science.org at Universitaetsbibliothek Bern on May 11, 2025</p></note>\n",
            "\t\t\t<note xmlns=\"http://www.tei-c.org/ns/1.0\" place=\"foot\" xml:id=\"foot_2\"><p>............................................................................................................................................................................................................................................................................................................................................RESEARCH | RESEARCH ARTICLEDownloaded from https://www.science.org at Universitaetsbibliothek Bern onMay 11, 2025   </p></note>\n",
            "\t\t\t<note xmlns=\"http://www.tei-c.org/ns/1.0\" place=\"foot\" xml:id=\"foot_3\"><p>aac4716-7 RESEARCH | RESEARCH ARTICLE Downloaded from https://www.science.org at Universitaetsbibliothek Bern on May 11, 2025</p></note>\n",
            "\t\t\t<note xmlns=\"http://www.tei-c.org/ns/1.0\" place=\"foot\" n=\"29\" xml:id=\"foot_4\"><p>April 2015; accepted 28 July 2015 10.1126/science.aac4716 aac4716-8 28 AUGUST 2015 â€¢ VOL 349 ISSUE 6251 sciencemag.org SCIENCE RESEARCH | RESEARCH ARTICLE Downloaded from https://www.science.org at Universitaetsbibliothek Bern on May 11, 2025</p></note>\n",
            "\t\t</body>\n",
            "\t\t<back>\n",
            "\n",
            "\t\t\t<div type=\"funding\">\n",
            "<div><p> Å tÄ›pÃ¡n BahnÃ­k,  Erica Baranski,  Leah Beyan,  Grace Binion,  Jan Crusius, 38 Jamie DeCoster,  NicolÃ¡s Della Penna, 39 Bobby den Bezemer,  Laura Dewitte, 40 David G. Dobolyi,  Geneva T. Dodson, 7 M. Brent Donnellan, 41 Ryan Donohue, 42 Rebecca A. Dore,  Angela Dorrough, 43,44  Anna Dreber, 45   Michelle Dugas,  Sylvia Eboigbe,  Casey Eggleston,  Jo Embley, 46 Sacha Epskamp,  Vivien Estel, 47 Frank J. Farach, 48,49   Jenelle Feather, 50 Anna Fedor,  BelÃ©n FernÃ¡ndez-Castilla, 52   Susann Fiedler, 44 James G. Field,  Stanka A. Fitneva, 53 Taru Flagan,  Amanda L. Forest, 54 Eskil Forsell, 45 Joshua D. Foster, 55  Michael C. Frank, 56 Rebecca S. Frazier,  Heather Fuchs, 38  Philip Gable, 57 Jeff Galak, 58 Elisa Maria Galliani, 59   Anup Gampa,  Sara Garcia, 60 Douglas Gazarian, 61   Elizabeth Gilbert,  Roger Giner-Sorolla, 46  Andreas GlÃ¶ckner, 44   Lars Goellner, 43 Jin X. Goh, 62 Rebecca Goldberg, 63 Patrick T. Goodbourn, 64 Shauna Gordon-McKeon, 65   Bryan Gorges,  Justin Goss, 66 Jesse Graham,  James A. Grange, 67 Jeremy Gray,  Joshua Hartshorne, 50 Fred Hasselman, 68  Timothy Hayes,  Emma Heikensten, 45  Felix Henninger, 69,44 John Hodsoll, 70,71   Taylor Holubar, 56 Gea Hoogendoorn,  Cathy O.-Y. Hung,  Nathali Immelman, 72  Vanessa C. Irsik, 73   Georg Jahn, 74  Frank JÃ¤kel, 75  Marc Jekel,  Magnus Johannesson, 45   Larissa G. Johnson, 76 David J. Johnson,  William J. Johnston, 77 Kai Jonas,  Heather Barry Kappes, 78 Kim Kelso,  Seung Kyung Kim, 56 Matthew Kirkhart, 79 Bennett Kleinberg, 80   Goran KneÅ¾eviÄ‡, 81 Franziska Maria Kolorz,  Tim Kuhlmann, 82 Yoram K. Kunkels,  Aamir Laique, 83 DaniÃ«l Lakens, 84 Kristin A. Lane, 61 Bethany Lassetter, 85 Ljiljana B. LazareviÄ‡, 81 Etienne P. LeBel, 86 Key Jung Lee, 56 Minha Lee,  Kristi Lemm, 87 Carmel A. Levitan, 88   Melissa Lewis, 89 Lin Lin,  Stephanie Lin, 56 Matthias Lippold,  Sean Mackinnon, 90   Heather N. Mainard,  Denise C. Marigold, 91 Daniel P. Martin, The <rs type=\"projectName\">Open Science Collaboration</rs> <rs type=\"person\">Alexander</rs> <rs type=\"person\">A. Aarts</rs>, <ref type=\"bibr\" target=\"#b0\">1</ref> <rs type=\"person\">Joanna E. Anderson</rs>, <ref type=\"bibr\" target=\"#b1\">2</ref> <rs type=\"person\">Christopher J. Anderson</rs>, <ref type=\"bibr\" target=\"#b2\">3</ref> Peter R. Attridge, <ref type=\"bibr\" target=\"#b3\">4,</ref><ref type=\"bibr\" target=\"#b4\">5</ref> Angela Attwood, <ref type=\"bibr\" target=\"#b5\">6</ref> Jordan Axt, <ref type=\"bibr\" target=\"#b6\">7</ref> Molly Babel, <ref type=\"bibr\" target=\"#b7\">8</ref> <rs type=\"person\">Å tÄ›pÃ¡n BahnÃ­k</rs>, <ref type=\"bibr\" target=\"#b8\">9</ref> <rs type=\"person\">Erica Baranski</rs>, <ref type=\"bibr\" target=\"#b9\">10</ref> Michael Barnett-Cowan, <ref type=\"bibr\" target=\"#b10\">11</ref> Elizabeth Bartmess, <ref type=\"bibr\" target=\"#b11\">12</ref> Jennifer Beer, <ref type=\"bibr\" target=\"#b12\">13</ref> Raoul Bell, <ref type=\"bibr\" target=\"#b13\">14</ref> Heather Bentley, <ref type=\"bibr\" target=\"#b4\">5</ref> <rs type=\"person\">Leah Beyan</rs>, <ref type=\"bibr\" target=\"#b4\">5</ref> <rs type=\"person\">Grace Binion</rs>, <ref type=\"bibr\" target=\"#b4\">5,</ref><ref type=\"bibr\" target=\"#b14\">15</ref> Denny Borsboom, <ref type=\"bibr\" target=\"#b15\">16</ref> Annick Bosch, <ref type=\"bibr\" target=\"#b16\">17</ref> Frank A. Bosco, <ref type=\"bibr\" target=\"#b17\">18</ref> Sara D. Bowman, <ref type=\"bibr\" target=\"#b18\">19</ref> Mark J. Brandt, <ref type=\"bibr\" target=\"#b19\">20</ref> Erin Braswell, <ref type=\"bibr\" target=\"#b18\">19</ref> Hilmar Brohmer, <ref type=\"bibr\" target=\"#b19\">20</ref> Benjamin T. Brown, <ref type=\"bibr\" target=\"#b4\">5</ref> <rs type=\"person\">Kristina Brown</rs>, <ref type=\"bibr\" target=\"#b4\">5</ref> Jovita BrÃ¼ning, <ref type=\"bibr\" target=\"#b20\">21,</ref><ref type=\"bibr\" target=\"#b21\">22</ref> Ann Calhoun-Sauls, <ref type=\"bibr\" target=\"#b22\">23</ref> Shannon P. Callahan, <ref type=\"bibr\" target=\"#b23\">24</ref> Elizabeth Chagnon, <ref type=\"bibr\" target=\"#b24\">25</ref> Jesse Chandler, <ref type=\"bibr\" target=\"#b25\">26,</ref><ref type=\"bibr\" target=\"#b26\">27</ref> Christopher R. Chartier, <ref type=\"bibr\" target=\"#b27\">28</ref> Felix Cheung, <ref type=\"bibr\" target=\"#b28\">29,</ref><ref type=\"bibr\" target=\"#b29\">30</ref> Cody D. Christopherson, <ref type=\"bibr\" target=\"#b30\">31</ref> Linda Cillessen, <ref type=\"bibr\" target=\"#b16\">17</ref> Russ Clay, <ref type=\"bibr\" target=\"#b31\">32</ref> Hayley Cleary, <ref type=\"bibr\" target=\"#b17\">18</ref> Mark D. Cloud, <ref type=\"bibr\" target=\"#b32\">33</ref> Michael Cohn, <ref type=\"bibr\" target=\"#b11\">12</ref> Johanna Cohoon, <ref type=\"bibr\" target=\"#b18\">19</ref> Simon Columbus, <ref type=\"bibr\" target=\"#b15\">16</ref> Andreas Cordes, <ref type=\"bibr\" target=\"#b33\">34</ref> Giulio Costantini, <ref type=\"bibr\" target=\"#b34\">35</ref> Leslie D. Cramblet Alvarez, <ref type=\"bibr\" target=\"#b35\">36</ref> Ed Cremata, <ref type=\"bibr\" target=\"#b36\">37</ref> Jan Crusius, <rs type=\"person\">38 Jamie DeCoster</rs>, <ref type=\"bibr\" target=\"#b6\">7</ref> Michelle A. DeGaetano, <ref type=\"bibr\" target=\"#b4\">5</ref> <rs type=\"person\">NicolÃ¡s Della Penna</rs>, <rs type=\"person\">39 Bobby den Bezemer</rs>, <ref type=\"bibr\" target=\"#b15\">16</ref> Marie K. Deserno, <ref type=\"bibr\" target=\"#b15\">16</ref> Olivia Devitt, <ref type=\"bibr\" target=\"#b4\">5</ref> <rs type=\"person\">Laura Dewitte</rs>, <rs type=\"person\">40 David G. Dobolyi</rs>, <ref type=\"bibr\" target=\"#b6\">7</ref> Geneva T. Dodson, <rs type=\"person\">7 M. Brent Donnellan</rs>, <rs type=\"person\">41 Ryan Donohue</rs>, <rs type=\"person\">42 Rebecca A. Dore</rs>, <ref type=\"bibr\" target=\"#b6\">7</ref> Angela Dorrough, 43,<rs type=\"person\">44 Anna Dreber</rs>, <rs type=\"person\">45 Michelle Dugas</rs>, <ref type=\"bibr\" target=\"#b24\">25</ref> Elizabeth W. Dunn, <ref type=\"bibr\" target=\"#b7\">8</ref> Kayleigh Easey, <ref type=\"bibr\" target=\"#b5\">6</ref> <rs type=\"person\">Sylvia Eboigbe</rs>, <ref type=\"bibr\" target=\"#b4\">5</ref> <rs type=\"person\">Casey Eggleston</rs>, <ref type=\"bibr\" target=\"#b6\">7</ref> Jo Embley, <rs type=\"person\">46 Sacha Epskamp</rs>, <ref type=\"bibr\" target=\"#b15\">16</ref> Timothy M. Errington, <ref type=\"bibr\" target=\"#b18\">19</ref> Vivien Estel, <rs type=\"person\">47 Frank J. Farach</rs>, 48,<rs type=\"person\">49 Jenelle Feather</rs>, <rs type=\"person\">50 Anna Fedor</rs>, <ref type=\"bibr\" target=\"#b38\">51</ref> BelÃ©n FernÃ¡ndez-Castilla, <rs type=\"person\">52 Susann Fiedler</rs>, <rs type=\"person\">44 James G. Field</rs>, <ref type=\"bibr\" target=\"#b17\">18</ref> Stanka A. Fitneva, <rs type=\"person\">53 Taru Flagan</rs>, <ref type=\"bibr\" target=\"#b12\">13</ref> Amanda L. Forest, <rs type=\"person\">54 Eskil Forsell</rs>, <rs type=\"person\">45 Joshua D. Foster</rs>, <rs type=\"person\">55 Michael C. Frank</rs>, <rs type=\"person\">56 Rebecca S. Frazier</rs>, <ref type=\"bibr\" target=\"#b6\">7</ref> Heather Fuchs, <rs type=\"person\">38 Philip Gable</rs>, <rs type=\"person\">57 Jeff Galak</rs>, <rs type=\"person\">58 Elisa Maria Galliani</rs>, <rs type=\"person\">59 Anup Gampa</rs>, <ref type=\"bibr\" target=\"#b6\">7</ref> Sara Garcia, <rs type=\"person\">60 Douglas Gazarian</rs>, <rs type=\"person\">61 Elizabeth Gilbert</rs>, <ref type=\"bibr\" target=\"#b6\">7</ref> Roger Giner-Sorolla, <rs type=\"person\">46 Andreas GlÃ¶ckner</rs>, <ref type=\"bibr\" target=\"#b33\">34,</ref><rs type=\"person\">44 Lars Goellner</rs>, <rs type=\"person\">43 Jin X. Goh</rs>, <rs type=\"person\">62 Rebecca Goldberg</rs>, <rs type=\"person\">63 Patrick T. Goodbourn</rs>, <rs type=\"person\">64 Shauna Gordon-McKeon</rs>, <rs type=\"person\">65 Bryan Gorges</rs>, <ref type=\"bibr\" target=\"#b18\">19</ref> Jessie Gorges, <ref type=\"bibr\" target=\"#b18\">19</ref> Justin Goss, <rs type=\"person\">66 Jesse Graham</rs>, <ref type=\"bibr\" target=\"#b36\">37</ref> James A. Grange, <rs type=\"person\">67 Jeremy Gray</rs>, <ref type=\"bibr\" target=\"#b28\">29</ref> Chris Hartgerink, <ref type=\"bibr\" target=\"#b19\">20</ref> Joshua Hartshorne, <rs type=\"person\">50 Fred Hasselman</rs>, <ref type=\"bibr\" target=\"#b16\">17,</ref><rs type=\"person\">68 Timothy Hayes</rs>, <ref type=\"bibr\" target=\"#b36\">37</ref> Emma Heikensten, <rs type=\"person\">45 Felix Henninger</rs>, 69,<rs type=\"person\">44 John Hodsoll</rs>, 70,<rs type=\"person\">71 Taylor Holubar</rs>, <rs type=\"person\">56 Gea Hoogendoorn</rs>, <ref type=\"bibr\" target=\"#b19\">20</ref> Denise J. Humphries, <ref type=\"bibr\" target=\"#b4\">5</ref> <rs type=\"person\">Cathy O.-Y. Hung</rs>, <ref type=\"bibr\" target=\"#b29\">30</ref> Nathali Immelman, <rs type=\"person\">72 Vanessa C. Irsik</rs>, <rs type=\"person\">73 Georg Jahn</rs>, <rs type=\"person\">74 Frank JÃ¤kel</rs>, <rs type=\"person\">75 Marc Jekel</rs>, <ref type=\"bibr\" target=\"#b33\">34</ref> Magnus Johannesson, <rs type=\"person\">45 Larissa G. Johnson</rs>, <rs type=\"person\">76 David J. Johnson</rs>, <ref type=\"bibr\" target=\"#b28\">29</ref> Kate M. Johnson, <ref type=\"bibr\" target=\"#b36\">37</ref> William J. Johnston, <rs type=\"person\">77 Kai Jonas</rs>, <ref type=\"bibr\" target=\"#b15\">16</ref> Jennifer A. Joy-Gaba, <ref type=\"bibr\" target=\"#b17\">18</ref> Heather Barry Kappes, <rs type=\"person\">78 Kim Kelso</rs>, <ref type=\"bibr\" target=\"#b35\">36</ref> Mallory C. Kidwell, <ref type=\"bibr\" target=\"#b18\">19</ref> Seung Kyung Kim, <rs type=\"person\">56 Matthew Kirkhart</rs>, <rs type=\"person\">79 Bennett Kleinberg</rs>, <ref type=\"bibr\" target=\"#b15\">16,</ref><rs type=\"person\">80 Goran KneÅ¾eviÄ‡</rs>, <rs type=\"person\">81 Franziska Maria Kolorz</rs>, <ref type=\"bibr\" target=\"#b16\">17</ref> Jolanda J. Kossakowski, <ref type=\"bibr\" target=\"#b15\">16</ref> Robert Wilhelm Krause, <ref type=\"bibr\" target=\"#b16\">17</ref> Job Krijnen, <ref type=\"bibr\" target=\"#b19\">20</ref> Tim Kuhlmann, <rs type=\"person\">82 Yoram K. Kunkels</rs>, <ref type=\"bibr\" target=\"#b15\">16</ref> Megan M. Kyc, <ref type=\"bibr\" target=\"#b32\">33</ref> Calvin K. Lai, <ref type=\"bibr\" target=\"#b6\">7</ref> Aamir Laique, <rs type=\"person\">83 DaniÃ«l Lakens</rs>, <rs type=\"person\">84 Kristin A. Lane</rs>, <rs type=\"person\">61 Bethany Lassetter</rs>, <rs type=\"person\">85 Ljiljana B. LazareviÄ‡</rs>, <rs type=\"person\">81 Etienne P. LeBel</rs>, <rs type=\"person\">86 Key Jung Lee</rs>, <rs type=\"person\">56 Minha Lee</rs>, <ref type=\"bibr\" target=\"#b6\">7</ref> Kristi Lemm, <rs type=\"person\">87 Carmel A. Levitan</rs>, <rs type=\"person\">88 Melissa Lewis</rs>, <rs type=\"person\">89 Lin Lin</rs>, <ref type=\"bibr\" target=\"#b29\">30</ref> Stephanie Lin, <rs type=\"person\">56 Matthias Lippold</rs>, <ref type=\"bibr\" target=\"#b33\">34</ref> Darren Loureiro, <ref type=\"bibr\" target=\"#b24\">25</ref> Ilse Luteijn, <ref type=\"bibr\" target=\"#b16\">17</ref> Sean Mackinnon, <rs type=\"person\">90 Heather N. Mainard</rs>, <ref type=\"bibr\" target=\"#b4\">5</ref> <rs type=\"person\">Denise C. Marigold</rs>, <rs type=\"person\">91 Daniel P. Martin</rs>, <ref type=\"bibr\" target=\"#b6\">7</ref> Tylar Martinez, 36 E.J. Masicampo, 92 Josh Matacotta, 93   Maya Mathur, 56 Michael May, 44,94  Nicole Mechin, 57 Pranjal Mehta, <ref type=\"bibr\" target=\"#b14\">15</ref> Johannes Meixner, <ref type=\"bibr\" target=\"#b20\">21,</ref>95  Alissa Melinger, 96 Jeremy K. Miller, 97 Mallorie Miller, 63 Katherine Moore, 42,98  Marcus MÃ¶schl, 99 Matt Motyl, 100  Stephanie M. MÃ¼ller, 47 Marcus Munafo, <ref type=\"bibr\" target=\"#b5\">6</ref> Koen I. Neijenhuijs, <ref type=\"bibr\" target=\"#b16\">17</ref> Taylor Nervi, <ref type=\"bibr\" target=\"#b27\">28</ref> Gandalf Nicolas, 101 Gustav Nilsonne, 102,103 Brian A. Nosek, <ref type=\"bibr\" target=\"#b6\">7,</ref><ref type=\"bibr\" target=\"#b18\">19</ref> MichÃ¨le B. Nuijten, <ref type=\"bibr\" target=\"#b19\">20</ref> Catherine Olsson, 50,104 Colleen Osborne, <ref type=\"bibr\" target=\"#b6\">7</ref> Lutz Ostkamp, 75 Misha Pavel, 62 Ian S. Penton-Voak, <ref type=\"bibr\" target=\"#b5\">6</ref> Olivia Perna, <ref type=\"bibr\" target=\"#b27\">28</ref> Cyril Pernet, 105 Marco Perugini, <ref type=\"bibr\" target=\"#b34\">35</ref> R. Nathan Pipitone, <ref type=\"bibr\" target=\"#b35\">36</ref> Michael Pitts, 89   Franziska Plessow, 99,106 Jason M. Prenoveau, 79 Rima-Maria Rahal, 44,<ref type=\"bibr\" target=\"#b15\">16</ref> Kate A. Ratliff, 107 David Reinhard, <ref type=\"bibr\" target=\"#b6\">7</ref> Frank Renkewitz, 47 Ashley A. Ricker, <ref type=\"bibr\" target=\"#b9\">10</ref> Anastasia Rigney, <ref type=\"bibr\" target=\"#b12\">13</ref> Andrew M. Rivers, <ref type=\"bibr\" target=\"#b23\">24</ref> Mark Roebke, 108 Abraham M. Rutchick, 109 Robert S. Ryan, 110 Onur Sahin, <ref type=\"bibr\" target=\"#b15\">16</ref> Anondah Saide, <ref type=\"bibr\" target=\"#b9\">10</ref> Gillian M. Sandstrom, <ref type=\"bibr\" target=\"#b7\">8</ref> David Santos, 111,112  Rebecca Saxe, 50   RenÃ© Schlegelmilch, 44,47 Kathleen Schmidt, 113 Sabine Scholz, 114 Larissa Seibel, <ref type=\"bibr\" target=\"#b16\">17</ref> Dylan Faulkner Selterman, <ref type=\"bibr\" target=\"#b24\">25</ref> Samuel Shaki, 115   William B. Simpson, 7 H. Colleen Sinclair, 63  Jeanine L. M. Skorinko, 116   Agnieszka Slowik, 117 Joel S. Snyder, 73  Courtney Soderberg, <ref type=\"bibr\" target=\"#b18\">19</ref> Carina Sonnleitner, 117 Nick Spencer, <ref type=\"bibr\" target=\"#b35\">36</ref> Jeffrey R. Spies, <ref type=\"bibr\" target=\"#b18\">19</ref> Sara Steegen, 40  Stefan Stieger, 82 Nina Strohminger, 118 Gavin B. Sullivan, 119 Thomas Talhelm, <ref type=\"bibr\" target=\"#b6\">7</ref> Megan Tapia, <ref type=\"bibr\" target=\"#b35\">36</ref> Anniek te Dorsthorst, <ref type=\"bibr\" target=\"#b16\">17</ref> Manuela Thomae, 72,120 Sarah L. Thomas, <ref type=\"bibr\" target=\"#b6\">7</ref> Pia Tio, <ref type=\"bibr\" target=\"#b15\">16</ref> Frits Traets, 40 Steve Tsang, 121 Francis Tuerlinckx, 40 Paul Turchan, 122 Milan ValÃ¡Å¡ek, 105 Anna E. van 't Veer, <ref type=\"bibr\" target=\"#b19\">20,</ref>123   Robbie Van Aert, <ref type=\"bibr\" target=\"#b19\">20</ref> Marcel van Assen, <ref type=\"bibr\" target=\"#b19\">20</ref> Riet van Bork, <ref type=\"bibr\" target=\"#b15\">16</ref> Mathijs van de Ven, <ref type=\"bibr\" target=\"#b16\">17</ref> Don van den Bergh, <ref type=\"bibr\" target=\"#b15\">16</ref> Marije van der Hulst, <ref type=\"bibr\" target=\"#b16\">17</ref> Roel van Dooren, <ref type=\"bibr\" target=\"#b16\">17</ref> Johnny van Doorn, 40 Daan R. van Renswoude, <ref type=\"bibr\" target=\"#b15\">16</ref> Hedderik van Rijn, 114 Wolf Vanpaemel, 40 Alejandro VÃ¡squez EcheverrÃ­a, 124 Melissa Vazquez, <ref type=\"bibr\" target=\"#b4\">5</ref> Natalia Velez, 56 Marieke Vermue, <ref type=\"bibr\" target=\"#b16\">17</ref> Mark Verschoor, <ref type=\"bibr\" target=\"#b19\">20</ref> Michelangelo Vianello, 59  Martin Voracek, 117 Gina Vuu, <ref type=\"bibr\" target=\"#b6\">7</ref> Eric-Jan Wagenmakers, <ref type=\"bibr\" target=\"#b15\">16</ref> Joanneke Weerdmeester, <ref type=\"bibr\" target=\"#b16\">17</ref> Ashlee Welsh, <ref type=\"bibr\" target=\"#b35\">36</ref> Erin C. Westgate, <ref type=\"bibr\" target=\"#b6\">7</ref> Joeri Wissink, <ref type=\"bibr\" target=\"#b19\">20</ref> Michael Wood, 72 Andy Woods, 125,<ref type=\"bibr\" target=\"#b5\">6</ref> Emily Wright, <ref type=\"bibr\" target=\"#b35\">36</ref> Sining Wu, 63   Marcel Zeelenberg, <ref type=\"bibr\" target=\"#b19\">20</ref> Kellylynn Zuni <ref type=\"bibr\" target=\"#b35\">36</ref> </p></div>\n",
            "\t\t\t</div>\n",
            "\t\t\t<listOrg type=\"funding\">\n",
            "\t\t\t\t<org type=\"funded-project\" xml:id=\"_aUgyjYH\">\n",
            "\t\t\t\t\t<orgName type=\"project\" subtype=\"full\">Open Science Collaboration</orgName>\n",
            "\t\t\t\t</org>\n",
            "\t\t\t</listOrg>\n",
            "\t\t\t<div type=\"annex\">\n",
            "<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>SUPPLEMENTARY MATERIALS</head><p>www.sciencemag.org/content/349/6251/aac4716/suppl/DC1 Materials and Methods Figs. S1 to S7 Tables <ref type=\"table\">S1 to S4</ref> References <ref type=\"bibr\">(38)</ref><ref type=\"bibr\">(39)</ref><ref type=\"bibr\">(40)</ref><ref type=\"bibr\">(41)</ref> </p></div>\t\t\t</div>\n",
            "\t\t\t<div type=\"references\">\n",
            "\n",
            "\t\t\t\t<listBibl>\n",
            "\n",
            "<biblStruct xml:id=\"b0\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Maximal specificity and lawlikeness in probabilistic explanation</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">C</forename><surname>Hempel</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1086/288197</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Philos. Sci</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">35</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"116\" to=\"133\" />\n",
            "\t\t\t<date type=\"published\" when=\"1968\">1968</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b1\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Studies in the logic of explanation</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">C</forename><surname>Hempel</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">P</forename><surname>Oppenheim</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1086/286983</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Philos. Sci</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">15</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"135\" to=\"175\" />\n",
            "\t\t\t<date type=\"published\" when=\"1948\">1948</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b2\">\n",
            "\t<monogr>\n",
            "\t\t<title level=\"m\" type=\"main\">Criticism and the Growth of Knowledge</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">I</forename><surname>Lakatos</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<editor>I. Lakatos, A. Musgrave</editor>\n",
            "\t\t<imprint>\n",
            "\t\t\t<date type=\"published\" when=\"1970\">1970</date>\n",
            "\t\t\t<publisher>Cambridge Univ. Press</publisher>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"170\" to=\"196\" />\n",
            "\t\t\t<pubPlace>London</pubPlace>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b3\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Appraising and amending theories: The strategy of Lakatosian defense and two principles that warrant it</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">P</forename><forename type=\"middle\">E</forename><surname>Meehl</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1207/s15327965pli0102_1</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Psychol. Inq</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">1</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"108\" to=\"141\" />\n",
            "\t\t\t<date type=\"published\" when=\"1990\">1990</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b4\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Strong Inference: Certain systematic methods of scientific thinking may produce much more rapid progress than others</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">J</forename><forename type=\"middle\">R</forename><surname>Platt</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1126/science.146.3642.347</idno>\n",
            "\t\t<idno>pmid: 17739513</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Science</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">146</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"347\" to=\"353\" />\n",
            "\t\t\t<date type=\"published\" when=\"1964\">1964</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b5\">\n",
            "\t<monogr>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">W</forename><forename type=\"middle\">C</forename><surname>Salmon</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<title level=\"m\">Introduction to the Philosophy of Science</title>\n",
            "\t\t<editor>\n",
            "\t\t\t<persName><forename type=\"first\">M</forename><forename type=\"middle\">H</forename><surname>Salmon</surname></persName>\n",
            "\t\t</editor>\n",
            "\t\t<editor>\n",
            "\t\t\t<persName><forename type=\"first\">Ed</forename></persName>\n",
            "\t\t</editor>\n",
            "\t\t<meeting><address><addrLine>Indianapolis</addrLine></address></meeting>\n",
            "\t\t<imprint>\n",
            "\t\t\t<publisher>Hackett Publishing Company</publisher>\n",
            "\t\t\t<date type=\"published\" when=\"1999\">1999</date>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"7\" to=\"41\" />\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b6\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Registered reports: A method to increase the credibility of published results</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">B</forename><forename type=\"middle\">A</forename><surname>Nosek</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">D</forename><surname>Lakens</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1027/1864-9335/a000192</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Soc. Psychol</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">45</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"137\" to=\"141\" />\n",
            "\t\t\t<date type=\"published\" when=\"2014\">2014</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b7\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Shall we really do it again? The powerful concept of replication is neglected in the social sciences</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">S</forename><surname>Schmidt</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1037/a0015108</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Rev. Gen. Psychol</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">13</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"90\" to=\"100\" />\n",
            "\t\t\t<date type=\"published\" when=\"2009\">2009</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b8\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Why most published research findings are false</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">J</forename><forename type=\"middle\">P A</forename><surname>Ioannidis</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1371/journal.pmed.0020124</idno>\n",
            "\t\t<idno>pmid: 16060722</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">PLOS Med</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">2</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\">124</biblScope>\n",
            "\t\t\t<date type=\"published\" when=\"2005\">2005</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b9\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Drug development: Raise standards for preclinical cancer research</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">C</forename><forename type=\"middle\">G</forename><surname>Begley</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">L</forename><forename type=\"middle\">M</forename><surname>Ellis</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1038/483531a</idno>\n",
            "\t\t<idno>pmid: 22460880</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Nature</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">483</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"531\" to=\"533\" />\n",
            "\t\t\t<date type=\"published\" when=\"2012\">2012</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b10\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Believe it or not: How much can we rely on published data on potential drug targets?</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">F</forename><surname>Prinz</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">T</forename><surname>Schlange</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">K</forename><surname>Asadullah</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1038/nrd3439-c1</idno>\n",
            "\t\t<idno>pmid: 21892149</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Nat. Rev. Drug Discov</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">10</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"712\" to=\"713\" />\n",
            "\t\t\t<date type=\"published\" when=\"2011\">2011</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b11\">\n",
            "\t<analytic>\n",
            "\t\t<title/>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">M</forename><surname>Mcnutt</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1126/science.1250475</idno>\n",
            "\t\t<idno>pmid: 24436391</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Reproducibility. Science</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">343</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\">229</biblScope>\n",
            "\t\t\t<date type=\"published\" when=\"2014\">2014</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b12\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Editors&apos; introduction to the special section on replicability in psychological science: A crisis of confidence?</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">H</forename><surname>Pashler</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">E.-J</forename><surname>Wagenmakers</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1177/1745691612465253</idno>\n",
            "\t\t<idno>pmid: 26168108</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Perspect. Psychol. Sci</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">7</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"528\" to=\"530\" />\n",
            "\t\t\t<date type=\"published\" when=\"2012\">2012</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b13\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Power failure: Why small sample size undermines the reliability of neuroscience</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">K</forename><forename type=\"middle\">S</forename><surname>Button</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1038/nrn3475</idno>\n",
            "\t\t<idno>pmid: 23571845</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Nat. Rev. Neurosci</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">14</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"365\" to=\"376\" />\n",
            "\t\t\t<date type=\"published\" when=\"2013\">2013</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b14\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Positive&quot; results increase down the hierarchy of the sciences</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">D</forename><surname>Fanelli</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1371/journal.pone.0010068</idno>\n",
            "\t\t<idno>pmid: 20383332</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">PLOS ONE</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">5</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\">10068</biblScope>\n",
            "\t\t\t<date type=\"published\" when=\"2010\">2010</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b15\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Consequences of prejudice against the null hypothesis</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">A</forename><forename type=\"middle\">G</forename><surname>Greenwald</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1037/h0076157</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Psychol. Bull</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">82</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"1\" to=\"20\" />\n",
            "\t\t\t<date type=\"published\" when=\"1975\">1975</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b16\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Do research literatures give correct answers?</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">G</forename><forename type=\"middle\">S</forename><surname>Howard</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1037/a0015468</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Rev. Gen. Psychol</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">13</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"116\" to=\"121\" />\n",
            "\t\t\t<date type=\"published\" when=\"2009\">2009</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b17\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Publication and other reporting biases in cognitive sciences: Detection, prevalence, and prevention</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">J</forename><forename type=\"middle\">P A</forename><surname>Ioannidis</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">M</forename><forename type=\"middle\">R</forename><surname>MunafÃ²</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">P</forename><surname>Fusar-Poli</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">B</forename><forename type=\"middle\">A</forename><surname>Nosek</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">S</forename><forename type=\"middle\">P</forename><surname>David</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1016/j.tics.2014.02.010</idno>\n",
            "\t\t<idno>pmid: 24656991</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Trends Cogn. Sci</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">18</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"235\" to=\"241\" />\n",
            "\t\t\t<date type=\"published\" when=\"2014\">2014</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b18\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Measuring the prevalence of questionable research practices with incentives for truth telling</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">L</forename><forename type=\"middle\">K</forename><surname>John</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">G</forename><surname>Loewenstein</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">D</forename><surname>Prelec</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1177/0956797611430953</idno>\n",
            "\t\t<idno>pmid: 22508865</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Psychol. Sci</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">23</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"524\" to=\"532\" />\n",
            "\t\t\t<date type=\"published\" when=\"2012\">2012</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b19\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Scientific utopia: II. Restructuring incentives and practices to promote truth over publishability</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">B</forename><forename type=\"middle\">A</forename><surname>Nosek</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">J</forename><forename type=\"middle\">R</forename><surname>Spies</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">M</forename><surname>Motyl</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1177/1745691612459058</idno>\n",
            "\t\t<idno>pmid: 26168121</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Perspect. Psychol. Sci</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">7</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"615\" to=\"631\" />\n",
            "\t\t\t<date type=\"published\" when=\"2012\">2012</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b20\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">The file drawer problem and tolerance for null results</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">R</forename></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1037/0033-2909.86.3.638</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Psychol. Bull</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">86</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"638\" to=\"641\" />\n",
            "\t\t\t<date type=\"published\" when=\"1979\">1979</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b21\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">What kind of empirical research should we publish, fund, and reward?: A different perspective</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">P</forename><surname>Rozin</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1111/j.1745-6924.2009.01151.x</idno>\n",
            "\t\t<idno>pmid: 26158991</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Perspect. Psychol. Sci</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">4</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"435\" to=\"439\" />\n",
            "\t\t\t<date type=\"published\" when=\"2009\">2009</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b22\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">J</forename><forename type=\"middle\">P</forename><surname>Simmons</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">L</forename><forename type=\"middle\">D</forename><surname>Nelson</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">U</forename><surname>Simonsohn</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1177/0956797611417632</idno>\n",
            "\t\t<idno>pmid: 22006061</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Psychol. Sci</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">22</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"1359\" to=\"1366\" />\n",
            "\t\t\t<date type=\"published\" when=\"2011\">2011</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b23\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">An open, large-scale, collaborative effort to estimate the reproducibility of psychological science</title>\n",
            "\t\t<author>\n",
            "\t\t\t<orgName type=\"collaboration\">Open Science Collaboration</orgName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1177/1745691612462588</idno>\n",
            "\t\t<idno>pmid: 26168127</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Perspect. Psychol. Sci</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">7</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"657\" to=\"660\" />\n",
            "\t\t\t<date type=\"published\" when=\"2012\">2012</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b24\">\n",
            "\t<monogr>\n",
            "\t\t<title level=\"m\" type=\"main\">Implementing Reproducible Computational Research (A Volume in The R Series)</title>\n",
            "\t\t<author>\n",
            "\t\t\t<orgName type=\"collaboration\">Open Science Collaboration</orgName>\n",
            "\t\t</author>\n",
            "\t\t<editor>V. Stodden, F. Leisch, R. Peng</editor>\n",
            "\t\t<imprint>\n",
            "\t\t\t<date type=\"published\" when=\"2014\">2014</date>\n",
            "\t\t\t<publisher>Taylor &amp; Francis</publisher>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"299\" to=\"323\" />\n",
            "\t\t\t<pubPlace>New York</pubPlace>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b25\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Theory of statistical estimation</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">R</forename><forename type=\"middle\">A</forename><surname>Fisher</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1017/S0305004100009580</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Math. Proc. Camb. Philos. Soc</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">22</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"700\" to=\"725\" />\n",
            "\t\t\t<date type=\"published\" when=\"1925\">1925</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b26\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Conducting meta-analyses in R with the metafor package</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">W</forename><surname>Viechtbauer</surname></persName>\n",
            "\t\t</author>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">J. Stat. Softw</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">36</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"1\" to=\"48\" />\n",
            "\t\t\t<date type=\"published\" when=\"2010\">2010</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b27\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Continuously cumulating meta-analysis and replicability</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">S</forename><forename type=\"middle\">L</forename><surname>Braver</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">F</forename><forename type=\"middle\">J</forename><surname>Thoemmes</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">R</forename><surname>Rosenthal</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1177/1745691614529796</idno>\n",
            "\t\t<idno>pmid: 26173268</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Perspect. Psychol. Sci</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">9</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"333\" to=\"342\" />\n",
            "\t\t\t<date type=\"published\" when=\"2014\">2014</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b28\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Small telescopes: Detectability and the evaluation of replication results</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">U</forename><surname>Simonsohn</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1177/0956797614567341</idno>\n",
            "\t\t<idno>pmid: 25800521</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Psychol. Sci</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">26</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"559\" to=\"569\" />\n",
            "\t\t\t<date type=\"published\" when=\"2015\">2015</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b29\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Calculating and reporting effect sizes to facilitate cumulative science: A practical primer for t-tests and ANOVAs</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">D</forename><surname>Lakens</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.3389/fpsyg.2013.00863</idno>\n",
            "\t\t<idno>pmid: 24324449</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Front. Psychol</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">4</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\">863</biblScope>\n",
            "\t\t\t<date type=\"published\" when=\"2013\">2013</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b30\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">The truth wears off: Is there something wrong with the scientific method?</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">J</forename><surname>Lehrer</surname></persName>\n",
            "\t\t</author>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">The New Yorker</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"52\" to=\"57\" />\n",
            "\t\t\t<date type=\"published\" when=\"2010\">2010</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b31\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Investigating variation in replicability: A &quot;many labs&quot; replication project</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">R</forename><surname>Klein</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1027/1864-9335/a000178</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Soc. Psychol</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">45</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"142\" to=\"152\" />\n",
            "\t\t\t<date type=\"published\" when=\"2014\">2014</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b32\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">The statistical power of abnormal-social psychological research: A review</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">J</forename><surname>Cohen</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1037/h0045186</idno>\n",
            "\t\t<idno>pmid: 13880271</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">J. Abnorm. Soc. Psychol</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">65</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"145\" to=\"153\" />\n",
            "\t\t\t<date type=\"published\" when=\"1962\">1962</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b33\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Publication decisions and their possible effects on inferences drawn from tests of significance-or vice versa</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">T</forename><forename type=\"middle\">D</forename><surname>Sterling</surname></persName>\n",
            "\t\t</author>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">J. Am. Stat. Assoc</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">54</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"30\" to=\"34\" />\n",
            "\t\t\t<date type=\"published\" when=\"1959\">1959</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b34\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">An open investigation of the reproducibility of cancer biology research</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">T</forename><forename type=\"middle\">M</forename><surname>Errington</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.7554/eLife.04333</idno>\n",
            "\t\t<idno>pmid: 25490932</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">eLife</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">3</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\">4333</biblScope>\n",
            "\t\t\t<date type=\"published\" when=\"2014\">2014</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b35\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Tracking replicability as a method of post-publication open evaluation</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">J</forename><forename type=\"middle\">K</forename><surname>Hartshorne</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">A</forename><surname>Schachner</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.3389/fncom.2012.00008</idno>\n",
            "\t\t<idno>pmid: 22403538</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Front. Comput. Neurosci</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">6</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\">8</biblScope>\n",
            "\t\t\t<date type=\"published\" when=\"2012\">2012</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b36\">\n",
            "\t<analytic>\n",
            "\t\t<title level=\"a\" type=\"main\">Promoting an open research culture</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">B</forename><forename type=\"middle\">A</forename><surname>Nosek</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno type=\"DOI\">10.1126/science.aab2374</idno>\n",
            "\t\t<idno>pmid: 26113702</idno>\n",
            "\t</analytic>\n",
            "\t<monogr>\n",
            "\t\t<title level=\"j\">Science</title>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">348</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\" from=\"1422\" to=\"1425\" />\n",
            "\t\t\t<date type=\"published\" when=\"2015\">2015</date>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "\t<note>ACKNOWLEDGMENTS In addition to the coauthors of this manuscript, there were many volunteers who contributed to project success</note>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b37\">\n",
            "\t<monogr>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">D</forename><surname>We</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">J</forename><surname>Acup</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">S</forename><surname>Anderson</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">R</forename><surname>Anzellotti</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">J</forename><forename type=\"middle\">D</forename><surname>Araujo</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">T</forename><surname>Arnal</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">R</forename><surname>Bates</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">R</forename><surname>Battleday</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">M</forename><surname>Bauchwitz</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">B</forename><surname>Bernstein</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">M</forename><surname>Blohowiak</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">E</forename><surname>Boffo</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">B</forename><surname>Bruneau</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">J</forename><surname>Chabot-Hanowell</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">P</forename><surname>Chan</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">A</forename><surname>Chu</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">B</forename><surname>Rosa</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">P</forename><surname>Deen</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">C</forename><surname>Digiacomo</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">N</forename><surname>Dogulu</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">C</forename><surname>Dufour</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">A</forename><surname>Fitzgerald</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">A</forename><surname>Foote</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">E</forename><surname>Garcia</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">C</forename><surname>Garcia</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">L</forename><surname>Gautreau</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">T</forename><surname>Germine</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">L</forename><surname>Gill</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">S</forename><forename type=\"middle\">D</forename><surname>Goldberg</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">H</forename><surname>Goldinger</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">D</forename><surname>Gweon</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">K</forename><surname>Haile</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">F</forename><surname>Hart</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">J</forename><surname>Hjorth</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">Ã…</forename><surname>Hoenig</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">B</forename><surname>Innes-Ker</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">R</forename><surname>Jansen</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">Y</forename><surname>Jersakova</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">Z</forename><surname>Jie</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">W</forename><forename type=\"middle\">K</forename><surname>Kaldy</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">A</forename><surname>Vong</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">J</forename><surname>Kenney</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">J</forename><surname>Kingston</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">A</forename><surname>Koster-Hale</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">R</forename><surname>Lam</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">D</forename><surname>Ledonne</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">E</forename><surname>Lumian</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">S</forename><surname>Luong</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">J</forename><surname>Man-Pui</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">A</forename><surname>Martin</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">T</forename><surname>Mauk</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">K</forename><surname>Mcelroy</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">T</forename><surname>Mcrae</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">K</forename><surname>Miller</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">M</forename><surname>Moser</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">A</forename><forename type=\"middle\">R</forename><surname>Mullarkey</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">J</forename><surname>Munoz</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">C</forename><surname>Ong</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">D</forename><forename type=\"middle\">S</forename><surname>Parks</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">D</forename><surname>Pate</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">H</forename><forename type=\"middle\">J M</forename><surname>Patron</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">M</forename><surname>Pennings</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">A</forename><surname>Penuliar</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">J</forename><forename type=\"middle\">P</forename><surname>Pfammatter</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">E</forename><surname>Shanoltz</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">E</forename><surname>Stevenson</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">H</forename><surname>Pichler</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">H</forename><surname>Raudszus</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">N</forename><surname>Richardson</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">T</forename><surname>Rothstein</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">S</forename><surname>Scherndl</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">S</forename><surname>Schrager</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">Y</forename><forename type=\"middle\">S</forename><surname>Shah</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">A</forename><surname>Tai</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">M</forename><surname>Skerry</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">J</forename><surname>Steinberg</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">H</forename><surname>Stoeterau</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">A</forename><surname>Tibboel</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">A</forename><surname>Tooley</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">C</forename><surname>Tullett</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">E</forename><surname>Vaccaro</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">A</forename><surname>Vergauwe</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">I</forename><surname>Watanabe</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">M</forename><forename type=\"middle\">H</forename><surname>Weiss</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">I</forename><forename type=\"middle\">I</forename><surname>White</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<title level=\"m\">1 Open Science Collaboration</title>\n",
            "\t\t<meeting><address><addrLine>Nuenen, Netherlands; Ottawa, ON, Canada</addrLine></address></meeting>\n",
            "\t\t<imprint>\n",
            "\t\t\t<publisher>Defense Research and Development Canada</publisher>\n",
            "\t\t\t<biblScope unit=\"volume\">2</biblScope>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b38\">\n",
            "\t<monogr>\n",
            "\t\t<title level=\"m\">Parmenides Center for the Study of Thinking</title>\n",
            "\t\t<meeting><address><addrLine>Munich, Germany; Madrid, Spain</addrLine></address></meeting>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">52</biblScope>\n",
            "\t\t</imprint>\n",
            "\t\t<respStmt>\n",
            "\t\t\t<orgName>Universidad Complutense de Madrid</orgName>\n",
            "\t\t</respStmt>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b39\">\n",
            "\t<monogr>\n",
            "\t\t<title level=\"m\" type=\"main\">King&apos;s College</title>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">Foundation</forename><surname>Maudsley</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><surname>Trust</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<imprint>\n",
            "\t\t\t<pubPlace>London, London, UK</pubPlace>\n",
            "\t\t</imprint>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b40\">\n",
            "\t<monogr>\n",
            "\t\t<title/>\n",
            "\t\t<author>\n",
            "\t\t\t<persName><forename type=\"first\">Mary</forename><surname>William</surname></persName>\n",
            "\t\t</author>\n",
            "\t\t<idno>109</idno>\n",
            "\t\t<imprint>\n",
            "\t\t\t<biblScope unit=\"volume\">102</biblScope>\n",
            "\t\t\t<biblScope unit=\"page\">110</biblScope>\n",
            "\t\t\t<pubPlace>Williamsburg, VA 23185; USA; Stockholm, Sweden; Stockholm, Sweden; New York; New York, NY 10003, USA; Edinburgh EH16 4SB, UK; Boston, MA 02215, USA; Gainesville, FL 32611, USA; Dayton, OH 45435, USA; Northridge, Northridge, CA 91330, USA</pubPlace>\n",
            "\t\t</imprint>\n",
            "\t\t<respStmt>\n",
            "\t\t\t<orgName>Stockholm University ; Karolinska Institute ; Center for Neural Science ; University ; Centre for Clinical Brain Sciences, The University of Edinburgh ; Department of Neurology, Beth Israel Deaconess Medical Center, Harvard Medical School ; Department of Psychology, University of Florida ; Department of Psychology, Wright State University ; California State University</orgName>\n",
            "\t\t</respStmt>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "<biblStruct xml:id=\"b41\">\n",
            "\t<monogr>\n",
            "\t\t<idno>120</idno>\n",
            "\t\t<title level=\"m\">Centre for Research in Psychology, Behavior and Achievement</title>\n",
            "\t\t<meeting><address><addrLine>Durham, NC 27708; USA; Coventry CV1 5FB, UK; Buckinghamshire MK7 6AA, UK; Shamshuipo, KLN, Hong Kong</addrLine></address></meeting>\n",
            "\t\t<imprint>\n",
            "\t\t\t<publisher>City University of Hong Kong</publisher>\n",
            "\t\t\t<biblScope unit=\"page\">122</biblScope>\n",
            "\t\t</imprint>\n",
            "\t\t<respStmt>\n",
            "\t\t\t<orgName>Duke University ; Coventry University ; The Open University</orgName>\n",
            "\t\t</respStmt>\n",
            "\t</monogr>\n",
            "</biblStruct>\n",
            "\n",
            "\t\t\t\t</listBibl>\n",
            "\t\t\t</div>\n",
            "\t\t</back>\n",
            "\t</text>\n",
            "</TEI>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we look at the output, we can see that we've got the body text in there, but we've also got a bunch of extra XML elements. We might care about those in another context, but right now we _only_ want the abstract and body text of the paper. We can fortunately use the `BeautifulSoup` module to strip these unwanted XML elements away. We will also remove the tables and figures and just focus on the paper text for this workshop."
      ],
      "metadata": {
        "id": "w1VImw-rD-h8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import BeautifulSoup\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Function to extract abstract and body as a single text object\n",
        "def extract_relevant_text(xml_content):\n",
        "    \"\"\"Extracts and combines the <abstract> and <body> elements into a single text block, excluding <note> elements inside <body>.\"\"\"\n",
        "    soup = BeautifulSoup(xml_content, \"xml\")\n",
        "\n",
        "    # extract and clean title\n",
        "    title = soup.find(\"title\")\n",
        "    title_text = title.get_text(separator=\" \") if title else \"\"\n",
        "\n",
        "    # Extract and clean abstract\n",
        "    abstract = soup.find(\"abstract\")\n",
        "    abstract_text = abstract.get_text(separator=\" \") if abstract else \"\"\n",
        "\n",
        "    # Extract and clean body, excluding <note> elements\n",
        "    body = soup.find(\"body\")\n",
        "    if body:\n",
        "        for note in body.find_all(\"note\"):\n",
        "            note.decompose()  # Remove <note> elements within <body>\n",
        "        body_text = body.get_text(separator=\" \")\n",
        "        for fig in body.find_all(\"figure\"):\n",
        "            fig.decompose()  # Remove <fig> elements within <body>\n",
        "        body_text = body.get_text(separator=\" \")\n",
        "    else:\n",
        "        body_text = \"\"\n",
        "\n",
        "    # Combine abstract and body into a single text object\n",
        "    full_text = f\"Title: {title_text}\\n\\nAbstract: {abstract_text}\\n\\nBody:\\n{body_text}\".strip()\n",
        "\n",
        "    return full_text"
      ],
      "metadata": {
        "id": "52eKi5k4EMiL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_paper_elements = extract_relevant_text(paper)"
      ],
      "metadata": {
        "id": "mwPobg2YE6iD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(extracted_paper_elements)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7y_mxoAE-kK",
        "outputId": "e05cdca9-9e66-43ea-f1e3-a04c85e13c73",
        "collapsed": true
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Estimating the reproducibility of psychological science Open Science Collaboration*\n",
            "\n",
            "Abstract: \n",
            " INTRODUCTION: Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error. \n",
            " RATIONALE: There is concern about the rate and predictors of reproducibility, but limited evidence. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a pre-RESEARCH \n",
            "\n",
            "\n",
            "Body:\n",
            "\n",
            " viously observed finding and is the means of establishing reproducibility of a finding with new data. We conducted a large-scale, collaborative effort to obtain an initial estimate of the reproducibility of psychological science. RESULTS  :  We conducted replications of 100 experimental and correlational studies published in three psychology journals using highpowered designs and original materials when available. There is no single standard for evaluating replication success. Here, we evaluated reproducibility using significance and P values, effect sizes, subjective assessments of replication teams, and meta-analysis of effect sizes. The mean effect size (r) of the replication effects (M r = 0.197, SD = 0.257) was half the magnitude of the mean effect size of the original effects (M r = 0.403, SD = 0.188), representing a substantial decline. Ninety-seven percent of original studies had significant results (P < .05). Thirty-six percent of replications had significant results; 47% of original effect sizes were in the 95% confidence interval of the replication effect size; 39% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams. CONCLUSION: No single indicator sufficiently describes replication success, and the five indicators examined here are not the only ways to evaluate reproducibility. Nonetheless, collectively these results offer a clear conclusion: A large portion of replications produced weaker evidence for the original findings despite using materials provided by the original authors, review in advance for methodological fidelity, and high statistical power to detect the original effect sizes. Moreover, correlational evidence is consistent with the conclusion that variation in the strength of initial evidence (such as original P value) was more predictive of replication success than variation in the characteristics of the teams conducting the research (such as experience and expertise). The latter factors certainly can influence replication success, but they did not appear to do so here. Reproducibility is not well understood because the incentives for individual scientists prioritize novelty over replication. Innovation is the engine of discovery and is vital for a productive, effective scientific enterprise. However, innovative ideas become old news fast. Journal reviewers and editors may dismiss a new test of a published idea as unoriginal. The claim that \"we already know this\" belies the uncertainty of scientific evidence. Innovation points out paths that are possible; replication points out paths that are likely; progress relies on both. Replication can increase certainty when findings are reproduced and promote innovation when they are not. This project provides accumulating evidence for many findings in psychological research and suggests that there is still more work to do to verify whether we know what we think we know. â–ª \n",
            " Estimating the reproducibility of psychological science Open Science Collaboration* â€  Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47% of original effect sizes were in the 95% confidence interval of the replication effect size; 39% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams. \n",
            " R eproducibility is a core principle of scientific progress  (1) (2) (3) (4) (5) (6) . Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Scientists attempt to transparently describe the methodology and resulting evidence used to support their claims. Other scientists agree or disagree whether the evidence supports the claims, citing theoretical or methodological reasons or by collecting new evidence. Such debates are meaningless, however, if the evidence being debated is not reproducible. Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a previously observed finding  (7, 8)  and is the means of establishing reproducibility of a finding with new data. A direct replication may not obtain the original result for a variety of reasons: Known or unknown differences between the replication and original study may moderate the size of an observed effect, the original result could have been a false positive, or the replication could produce a false negative. False positives and false negatives provide misleading information about effects, and failure to identify the necessary and sufficient conditions to reproduce a finding indicates an incomplete theoretical understanding. Direct replication provides the opportunity to assess and improve reproducibility. There is plenty of concern (9-13) about the rate and predictors of reproducibility but limited evidence. In a theoretical analysis, Ioannidis estimated that publishing and analytic practices make it likely that more than half of research results are false and therefore irreproducible  (9) . Some empirical evidence supports this analysis. In cell biology, two industrial laboratories reported success replicating the original results of landmark findings in only 11 and 25% of the attempted cases, respectively  (10, 11) . These numbers are stunning but also difficult to interpret because no details are available about the studies, methodology, or results. With no transparency, the reasons for low reproducibility cannot be evaluated. Other investigations point to practices and incentives that may inflate the likelihood of obtaining false-positive results in particular or irreproducible results more generally. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results  (12) (13) (14) (15) (16) (17) (18) (19) (20) (21) (22) (23) . We were inspired to address the gap in direct empirical evidence about reproducibility. In this Research Article, we report a large-scale, collaborative effort to obtain an initial estimate of the reproducibility of psychological science. \n",
            " Method Starting in November 2011, we constructed a protocol for selecting and conducting highquality replications  (24) . Collaborators joined the project, selected a study for replication from the available studies in the sampling frame, and were guided through the replication protocol. The replication protocol articulated the process of selecting the study and key effect from the available articles, contacting the original authors for study materials, preparing a study protocol and analysis plan, obtaining review of the protocol by the original authors and other members within the present project, registering the protocol publicly, conducting the replication, writing the final report, and auditing the process and analysis for quality control. Project coordinators facilitated each step of the process and maintained the protocol and project resources. Replication materials and data were required to be archived publicly in order to maximize transparency, accountability, and reproducibility of the project ( https://osf.io/ezcuj ). In total, 100 replications were completed by 270 contributing authors. There were many different research designs and analysis strategies in the original research. Through consultation with original authors, obtaining original materials, and internal review, replications maintained high fidelity to the original designs. Analyses converted results to a common effect size metric [correlation coefficient (r)] with confidence intervals (CIs). The units of analysis for inferences about reproducibility were the original and replication study effect sizes. The resulting open data set provides an initial estimate of the reproducibility of psychology and correlational data to support development of hypotheses about the causes of reproducibility. \n",
            " Sampling frame and study selection We constructed a sampling frame and selection process to minimize selection biases and maximize generalizability of the accumulated evidence. Simultaneously, to maintain high quality, within this sampling frame we matched individual replication projects with teams that had relevant interests and expertise. We pursued a quasi-random sample by defining the sampling frame as 2008 articles of three important psychology journals: Psychological Science (PSCI), Journal of Personality and Social Psychology (JPSP), and Journal of Experimental Psychology: Learning, Memory, and Cognition (JEP: LMC). The first is a premier outlet for all psychological research; the second and third are leading disciplinary-specific journals for social psychology and cognitive psychology, respectively [more information is available in  (24) ]. These were selected a priori in order to (i) provide a tractable sampling frame that would not plausibly bias reproducibility estimates, (ii) enable comparisons across journal types and subdisciplines, (iii) fit with the range of expertise available in the initial collaborative team, (iv) be recent enough to obtain original materials, (v) be old enough to obtain meaningful indicators of citation impact, and (vi) represent psychology subdisciplines that have a high frequency of studies that are feasible to conduct at relatively low cost. The first replication teams could select from a pool of the first 20 articles from each journal, starting with the first article published in the first 2008 issue. Project coordinators facilitated matching articles with replication teams by interests and expertise until the remaining articles were difficult to match. If there were still interested teams, then another 10 articles from one or more of the three journals were made available from the sampling frame. Further, project coordinators actively recruited teams from the community with relevant experience for particular articles. This approach balanced competing goals: minimizing selection bias by having only a small set of articles available at a time and matching studies with replication teams' interests, resources, and expertise. By default, the last experiment reported in each article was the subject of replication. This decision established an objective standard for study selection within an article and was based on the intuition that the first study in a multiplestudy article (the obvious alternative selection strategy) was more frequently a preliminary demonstration. Deviations from selecting the last experiment were made occasionally on the basis of feasibility or recommendations of the original authors. Justifications for deviations were reported in the replication reports, which were made available on the Open Science Framework (OSF) ( http://osf.io/ezcuj ). In total, 84 of the 100 completed replications (84%) were of the last reported study in the article. On average, the to-be-replicated articles contained 2.99 studies (SD = 1.78) with the following distribution: 24 single study, 24 two studies, 18 three studies, 13 four studies, 12 five studies, 9 six or more studies. All following summary statistics refer to the 100 completed replications. For the purposes of aggregating results across studies to estimate reproducibility, a key result from the selected experiment was identified as the focus of replication. The key result had to be represented as a single statistical inference test or an effect size. In most cases, that test was a t test, F test, or correlation coefficient. This effect was identified before data collection or analysis and was presented to the original authors as part of the design protocol for critique. Original authors occasionally suggested that a different effect be used, and by default, replication teams deferred to original authors' judgments. Nonetheless, because the single effect came from a single study, it is not necessarily the case that the identified effect was central to the overall aims of the article. In the individual replication reports and subjective assessments of replication outcomes, more than a single result could be examined, but only the result of the single effect was considered in the aggregate analyses [additional details of the general protocol and individual study methods are provided in the supplementary materials and (  25 )]. In total, there were 488 articles in the 2008 issues of the three journals. One hundred fiftyeight of these (32%) became eligible for selection for replication during the project period, between November 2011 and December 2014. From those, 111 articles (70%) were selected by a replication team, producing 113 replications. Two articles had two replications each (supplementary materials). And 100 of those (88%) replications were completed by the project deadline for inclusion in this aggregate report. After being claimed, some studies were not completed because the replication teams ran out of time or could not devote sufficient resources to completing the study. By journal, replications were completed for 39 of 64 (61%) articles from PSCI, 31 of 55 (56%) articles from JPSP, and 28 of 39 (72%) articles from JEP:LMC. The most common reasons for failure to match an article with a team were feasibility constraints for conducting the research. Of the 47 articles from the eligible pool that were not claimed, six (13%) had been deemed infeasible to replicate because of time, resources, instrumentation, dependence on historical events, or hard-to-access samples. The remaining 41 (87%) were eligible but not claimed. These often required specialized samples (such as macaques or people with autism), resources (such as eye tracking machines or functional magnetic resonance imaging), or knowledge making them difficult to match with teams. \n",
            " Aggregate data preparation Each replication team conducted the study, analyzed their data, wrote their summary report, and completed a checklist of requirements for sharing the materials and data. Then, independent reviewers and analysts conducted a projectwide audit of all individual projects, materials, data, and reports. A description of this review is available on the OSF ( https://osf.io/xtine ). Moreover, to maximize reproducibility and accuracy, the analyses for every replication study were reproduced by another analyst independent of the replication team using the R statistical programming language and a standardized analytic format. A controller R script was created to regenerate the entire analysis of every study and recreate the master data file. This R script, available at  https://osf.io/fkmwg , can be executed to reproduce the results of the individual studies. A comprehensive description of this reanalysis process is available publicly ( https://osf.io/a2eyg ). \n",
            " Measures and moderators We assessed features of the original study and replication as possible correlates of reproducibility and conducted exploratory analyses to inspire further investigation. These included characteristics of the original study such as the publishing journal; original effect size, P value, and sample size; experience and expertise of the original research team; importance of the effect, with indicators such as the citation impact of the article; and rated surprisingness of the effect. We also assessed characteristics of the replication such as statistical power and sample size, experience and expertise of the replication team, independently assessed challenge of conducting an effective replication, and self-assessed quality of the replication effort. Variables such as the P value indicate the statistical strength of evidence given the null hypothesis, and variables such as \"effect surprisingness\" and \"expertise of the team\" indicate qualities of the topic of study and the teams studying it, respectively. The master data file, containing these and other variables, is available for exploratory analysis ( https://osf.io/5wup8 ). It is possible to derive a variety of hypotheses about predictors of reproducibility. To reduce the likelihood of false positives due to many tests, we aggregated some variables into summary indicators: experience and expertise of original team, experience and expertise of replication team, challenge of replication, self-assessed quality of repli-cation, and importance of the effect. We had no a priori justification to give some indicators stronger weighting over others, so aggregates were created by standardizing [mean (M) = 0, SD = 1] the individual variables and then averaging to create a single index. In addition to the publishing journal and subdiscipline, potential moderators included six characteristics of the original study and five characteristics of the replication (supplementary materials). \n",
            " Publishing journal and subdiscipline Journals' different publishing practices may result in a selection bias that covaries with reproducibility. Articles from three journals were made available for selection: JPSP (n = 59 articles), JEP: LMC (n = 40 articles), and PSCI (n = 68 articles). From this pool of available studies, replications were selected and completed from JPSP (n = 32 studies), JEP:LMC (n = 28 studies), and PSCI (n = 40 studies) and were coded as representing cognitive (n = 43 studies) or social-personality (n = 57 studies) subdisciplines. Four studies that would ordinarily be understood as \"developmental psychology\" because of studying children or infants were coded as having a cognitive or social emphasis. Reproducibility may vary by subdiscipline in psychology because of differing practices. For example, within-subjects designs are more common in cognitive than social psychology, and these designs often have greater power to detect effects with the same number of participants. \n",
            " Statistical analyses There is no single standard for evaluating replication success  (25) . We evaluated reproducibility using significance and P values, effect sizes, subjective assessments of replication teams, and meta-analyses of effect sizes. All five of these indicators contribute information about the relations between the replication and original finding and the cumulative evidence about the effect and were positively correlated with one another (r ranged from 0.22 to 0.96, median r = 0.57). Results are summarized in Table  1 , and full details of analyses are in the supplementary materials. \n",
            " Significance and P values Assuming a two-tailed test and significance or a level of 0.05, all test results of original and replication studies were classified as statistically significant (P â‰¤ 0.05) and nonsignificant (P > 0.05). However, original studies that interpreted nonsignificant P values as significant were coded as significant (four cases, all with P values < 0.06). Using only the nonsignificant P values of the replication studies and applying Fisher's method  (26) , we tested the hypothesis that these studies had \"no evidential value\" (the null hypothesis of zero-effect holds for all these studies). We tested the hypothesis that the proportions of statistically significant results in the original and replication studies are equal using the McNemar test for paired nominal data and calculated a CI of the reproducibility parameter. Second, we compared the central tendency of the distribution of P values of original and replication studies using the Wilcoxon signedrank test and the t test for dependent samples. For both tests, we only used study-pairs for which both P values were available. \n",
            " Effect sizes We transformed effect sizes into correlation coefficients whenever possible. Correlation coefficients have several advantages over other effect size measures, such as Cohen's d. Correlation coefficients are bounded, well known, and therefore more readily interpretable. Most important for our purposes, analysis of correlation coefficients is straightforward because, after ap-plying the Fisher transformation, their standard error is only a function of sample size. Formulas and code for converting test statistics z, F, t, and c 2 into correlation coefficients are provided in the appendices at  http://osf.io/ezum7 . To be able to compare and analyze correlations across studypairs, the original study's effect size was coded as positive; the replication study's effect size was coded as negative if the replication study's effect was opposite to that of the original study. We compared effect sizes using four tests. We compared the central tendency of the effect size distributions of original and replication studies using both a paired two-sample t test and the Wilcoxon signed-rank test. Third, we computed the proportion of study-pairs in which the effect of the original study was stronger than in the replication study and tested the hypothesis that this proportion is 0.5. For this test, we included findings for which effect size measures were available but no correlation coefficient could be computed (for example, if a regression coefficient was reported but not its test statistic). Fourth, we calculated \"coverage,\" or the proportion of study-pairs in which the effect of the original study was in the CI of the effect of the replication study, and compared this with the expected proportion using a goodness-of-fit c 2 test. We carried SCIENCE sciencemag.org 28 AUGUST 2015 â€¢ VOL 349 ISSUE 6251 aac4716-3 Table  2 . Spearman's rank-order correlations of reproducibility indicators with summary original and replication study characteristics. Effect size difference computed after converting r to Fisher's z. df/N refers to the information on which the test of the effect was based (for example, df of t test, denominator df of F test, sample size -3 of correlation, and sample size for z and c 2 ). Four original results had P values slightly higher than 0.05 but were considered positive results in the original article and are treated that way here. Exclusions (explanation provided in supplementary materials, A3) are \"replications P < .05\" (3 original nulls excluded; n = 97 studies), \"effect size difference\" (3 excluded; n = 97 studies); \"meta-analytic mean estimates\" (27 excluded; n = 73 studies); and, \"percent original effect size within replication 95% CI\" (5 excluded, n = 95 studies).    1 . Summary of reproducibility rates and effect sizes for original and replication studies overall and by journal/discipline. df/N refers to the information on which the test of the effect was based (for example, df of t test, denominator df of F test, sample size -3 of correlation, and sample size for z and c 2 ). Four original results had P values slightly higher than 0.05 but were considered positive results in the original article and are treated that way here. Exclusions (explanation provided in supplementary materials, A3) are \"replications P < 0.05\" (3 original nulls excluded; n = 97 studies); \"mean original and replication effect sizes\" (3 excluded; n = 97 studies); \"meta-analytic mean estimates\" (27 excluded; n = 73 studies); \"percent meta-analytic (P < 0.05)\" (25 excluded; n = 75 studies); and, \"percent original effect size within replication 95% CI\" (5 excluded, n = 95 studies).  out this test on the subset of study pairs in which both the correlation coefficient and its standard error could be computed [we refer to this data set as the meta-analytic (MA) subset]. Standard errors could only be computed if test statistics were r, t, or F(1,df 2 ). The expected proportion is the sum over expected probabilities across studypairs. The test assumes the same population effect size for original and replication study in the same study-pair. For those studies that tested the effect with F(df 1 > 1, df 2 ) or c 2 , we verified coverage using other statistical procedures (computational details are provided in the supplementary materials). \n",
            " Effect size comparison \n",
            " Meta-analysis combining original and replication effects We conducted fixed-effect meta-analyses using the R package metafor (  27 ) on Fisher-transformed correlations for all study-pairs in subset MA and on study-pairs with the odds ratio as the dependent variable. The number of times the CI of all these meta-analyses contained 0 was calculated. For studies in the MA subset, estimated effect sizes were averaged and analyzed by discipline. Subjective assessment of \"Did it replicate?\" In addition to the quantitative assessments of replication and effect estimation, we collected subjective assessments of whether the replication provided evidence of replicating the original result. In some cases, the quantitative data anticipate a straightforward subjective assessment of replication. For more complex designs, such as multivariate interaction effects, the quantitative analysis may not provide a simple interpretation. For subjective assessment, replication teams answered \"yes\" or \"no\" to the question, \"Did your results replicate the original effect?\" Additional subjective variables are available for analysis in the full data set. \n",
            " Analysis of moderators We correlated the five indicators evaluating reproducibility with six indicators of the origi-nal study (original P value, original effect size, original sample size, importance of the effect, surprising effect, and experience and expertise of original team) and seven indicators of the replication study (replication P value, replication effect size, replication power based on original effect size, replication sample size, challenge of conducting replication, experience and expertise of replication team, and self-assessed quality of replication) (Table  2 ). As follow-up, we did the same with the individual indicators comprising the moderator variables (tables S3 and S4). \n",
            " Results \n",
            " Evaluating replication effect against null hypothesis of no effect A straightforward method for evaluating replication is to test whether the replication shows a statistically significant effect (P < 0.05) with the same direction as the original study. This dichotomous vote-counting method is intuitively appealing and consistent with common heuristics used to decide whether original studies \"worked.\" Ninety-seven of 100 (97%) effects from original studies were positive results (four had P values falling a bit short of the 0.05 criterion-P = 0.0508, 0.0514, 0.0516, and 0.0567but all of these were interpreted as positive effects). On the basis of only A key weakness of this method is that it treats the 0.05 threshold as a bright-line criterion between replication success and failure  (28) . It could be that many of the replications fell just short of the 0.05 criterion. The density plots of P values for original studies (mean P value = 0.028) and replications (mean P value = 0.302) are shown in Fig.  1 , left. The 64 nonsignificant P values for replications were distributed widely. When there is no effect to detect, the null distribution of P values is uniform. This distribution deviated slightly from uniform with positive skew, however, suggesting that at least one replication could be a false negative, c 2 (128) = 155.83, P = 0.048. Nonetheless, the wide distribution of P values suggests against insufficient power as the only explanation for failures to replicate. A scatterplot of original compared with replication study P values is shown in Fig.  2 . \n",
            " Evaluating replication effect against original effect size A complementary method for evaluating replication is to test whether the original effect size is within the 95% CI of the effect size estimate from the replication. For the subset of 73 studies in which the standard error of the correlation could be computed, 30 (41.1%) of the replication CIs contained the original effect size (significantly lower than the expected value of 78.5%, P < 0.001) (supplementary materials). For 22 studies using other test statistics [F(df 1 > 1, df 2 ) and c 2 ], 68.2% of CIs contained the effect size of the original study. Overall, this analysis suggests a 47.4% replication success rate. This method addresses the weakness of the first test that a replication in the same direction and a P value of 0.06 may not be significantly different from the original result. However, the method will also indicate that a replication \"fails\" when the direction of the effect is the same but the replication effect size is significantly smaller than the original effect size  (29) . Also, the replication \"succeeds\" when the result is near zero but not estimated with sufficiently high precision to be distinguished from the original effect size. \n",
            " Comparing original and replication effect sizes Comparing the magnitude of the original and replication effect sizes avoids special emphasis on P values. Overall, original study effect sizes (M = 0.403, SD = 0.188) were reliably larger than replication effect sizes (M = 0.197, SD = 0.257), Wilcoxon's W = 7137, P < 0.001. Of the 99 studies for which an effect size in both the original and replication study could be calculated  (30) , 82 showed a stronger effect size in the original study (82.8%; P < 0.001, binomial test) (Fig.  1 , right). Original and replication effect sizes were positively correlated (Spearman's r = 0.51, P < 0.001). A scatterplot of the original and replication effect sizes is presented in Fig.  3 . \n",
            " Combining original and replication effect sizes for cumulative evidence The disadvantage of the descriptive comparison of effect sizes is that it does not provide information about the precision of either estimate or resolution of the cumulative evidence for the effect. This is often addressed by computing a meta-analytic estimate of the effect sizes by combining the original and replication studies  (28) . This approach weights each study by the inverse of its variance and uses these weighted estimates of effect size to estimate cumulative evidence and precision of the effect. Using a fixed-effect model, 51 of the 75 (68%) effects for which a meta-analytic estimate could be computed had 95% CIs that did not include 0. One qualification about this result is the possibility that the original studies have inflated effect sizes due to publication, selection, reporting, or other biases  (9, (12) (13) (14) (15) (16) (17) (18) (19) (20) (21) (22) (23) . In a discipline with low-powered research designs and an emphasis on positive results for publication, effect sizes will be systematically overestimated in the published literature. There is no publication bias in the replication studies because all results are reported. Also, there are no selection or reporting biases because all were confirmatory tests based on pre-analysis plans. This maximizes the interpretability of the replication P values and effect estimates. If publication, selection, and reporting biases completely explain the effect differences, then the replication estimates would be a better estimate of the effect size than would the metaanalytic and original results. However, to the extent that there are other influences, such as moderation by sample, setting, or quality of replication, the relative bias influencing original and replication effect size estimation is unknown. \n",
            " Subjective assessment of \"Did it replicate?\" In addition to the quantitative assessments of replication and effect estimation, replication teams provided a subjective assessment of replication success of the study they conducted. Subjective assessments of replication success were very similar to significance testing results (39 of 100 successful replications), including evaluating \"success\" for two null replications when the original study reported a null result and \"failure\" for a P < 0.05 replication when the original result was a null. \n",
            " Correlates of reproducibility The overall replication evidence is summarized in Table  1  across the criteria described above and then separately by journal/discipline. Considering significance testing, reproducibility was stronger in studies and journals representing cognitive psychology than social psychology topics. For example, combining across journals, 14 of 55 (25%) of social psychology effects replicated by the P < 0.05 criterion, whereas 21 of 42 (50%) of cognitive psychology effects did so. Simultaneously, all journals and disciplines showed substantial and similar [c 2 (3) = 2.45, P = 0.48] declines in effect size in the replications compared with the original studies. The difference in significance testing results between fields appears to be partly a function of weaker original effects in social psychology studies, particularly in JPSP, and perhaps of the greater frequency of high-powered within-subjects manipulations and repeated measurement designs in cognitive psychology as suggested by high power despite relatively small participant samples. Further, the type of test was associated with replication success. Among original, significant effects, 23 of the 49 (47%) that tested main or simple effects replicated at P < 0.05, but just 8 of the 37 (22%) that tested interaction effects did. Correlations between reproducibility indicators and characteristics of replication and original studies are provided in Table  2 . A negative correlation of replication success with the original study P value indicates that the initial strength of evidence is predictive of reproducibility. For example, 26 of 63 (41%) original studies with P < 0.02 achieved P < 0.05 in the replication, whereas 6 of 23 (26%) that had a P value between 0.02 < P < 0.04 and 2 of 11 (18%) that had a P value > 0.04 did so (Fig.  2 ). Almost two thirds (20 of 32, 63%) of original studies with P < 0.001 had a significant P value in the replication. Larger original effect sizes were associated with greater likelihood of achieving P < 0.05 (r = 0.304) and a greater effect size difference between original and replication (r = 0.279). Moreover, replication power was related to replication success via significance testing (r = 0.368) but not with the effect size difference between original and replication (r = -0.053). Comparing effect sizes across indicators, surprisingness of the original effect, and the challenge of conducting the replication were related to replication success for some indicators. Surprising effects were less reproducible, as were effects for which it was more challenging to conduct the replication. Last, there was little evidence that perceived importance of the effect, expertise of the original or replication teams, or self-assessed quality of the replication accounted for meaningful variation in reproducibility across indicators. Replication success was more consistently related to the original strength of evidence (such as original P value, effect size, and effect tested) than to characteristics of the teams and implementation of the replication (such as expertise, quality, or challenge of conducting study) (tables S3 and S4). \n",
            " Discussion No single indicator sufficiently describes replication success, and the five indicators examined here are not the only ways to evaluate reproducibility. Nonetheless, collectively, these results offer a clear conclusion: A large portion of replications produced weaker evidence for the original findings (31) despite using materials provided by the original authors, review in advance for methodological fidelity, and high statistical power to detect the original effect sizes. Moreover, correlational evidence is consistent with the conclusion that variation in the strength of initial evidence (such as original P value) was more predictive of replication success than was variation in the characteristics of the teams conducting the research (such as experience and expertise). The latter factors certainly can influence replication success, but the evidence is that they did not systematically do so here. Other investigators may develop alternative indicators to explore further the role of expertise and quality in reproducibility on this open data set. \n",
            " Insights on reproducibility It is too easy to conclude that successful replication means that the theoretical understanding of the original finding is correct. Direct replication mainly provides evidence for the reliability of a result. If there are alternative explanations for the original finding, those alternatives could likewise account for the replication. Understanding is achieved through multiple, diverse investigations that provide converging support for a theoretical interpretation and rule out alternative explanations. It is also too easy to conclude that a failure to replicate a result means that the original evidence was a false positive. Replications can fail if the replication methodology differs from the original in ways that interfere with observing the effect. We conducted replications designed to minimize a priori reasons to expect a different result by using original materials, engaging original authors for review of the designs, and conducting internal reviews. Nonetheless, unanticipated factors in the sample, setting, or procedure could still have altered the observed effect magnitudes  (32) . More generally, there are indications of cultural practices in scientific communication that may be responsible for the observed results. Lowpower research designs combined with publication bias favoring positive results together produce a literature with upwardly biased effect sizes  (14, 16, 33, 34) . This anticipates that replication effect sizes would be smaller than original studies on a routine basis-not because of differences in implementation but because the original study effect sizes are affected by publication and reporting bias, and the replications are not. Consistent with this expectation, most replication effects were smaller than original results, and reproducibility success was correlated with indicators of the strength of initial evidence, such as lower original P values and larger effect sizes. This suggests publication, selection, and reporting biases as plausible explanations for the difference between original and replication effects. The replication studies significantly reduced these biases because replication preregistration and pre-analysis plans ensured confirmatory tests and reporting of all results. The observed variation in replication and original results may reduce certainty about the statistical inferences from the original studies but also provides an opportunity for theoretical innovation to explain differing outcomes, and then new research to test those hypothesized explanations. The correlational evidence, for example, suggests that procedures that are more challenging to execute may result in less reproducible results, and that more surprising original effects may be less reproducible than less surprising original effects. Further, systematic, repeated replication efforts that fail to identify conditions under which the original finding can be observed reliably may reduce confidence in the original finding. \n",
            " Implications and limitations The present study provides the first open, systematic evidence of reproducibility from a sample of studies in psychology. We sought to maximize generalizability of the results with a structured process for selecting studies for replication. However, it is unknown the extent to which these findings extend to the rest of psychology or other disciplines. In the sampling frame itself, not all articles were replicated; in each article, only one study was replicated; and in each study, only one statistical result was subject to replication. More resource-intensive studies were less likely to be included than were less resource-intensive studies. Although study selection bias was reduced by the sampling frame and selection strategy, the impact of selection bias is unknown. We investigated the reproducibility rate of psychology not because there is something special about psychology, but because it is our discipline. Concerns about reproducibility are widespread across disciplines (9-21). Reproducibility is not well understood because the incentives for individual scientists prioritize novelty over replication  (20) . If nothing else, this project demonstrates that it is possible to conduct a large-scale examination of reproducibility despite the incentive barriers. Here, we conducted single-replication attempts of many effects obtaining broad-and-shallow evidence. These data provide information about reproducibility in general but little precision about individual effects in particular. A complementary narrow-and-deep approach is characterized by the Many Labs replication projects  (32) . In those, many replications of single effects allow precise estimates of effect size but result in generalizability that is circumscribed to those individual effects. Pursuing both strategies across disciplines, such as the ongoing effort in cancer biology  (35) , would yield insight about common and distinct aac4716-6 challenges and may cross-fertilize strategies so as to improve reproducibility. Because reproducibility is a hallmark of credible scientific evidence, it is tempting to think that maximum reproducibility of original results is important from the onset of a line of inquiry through its maturation. This is a mistake. If initial ideas were always correct, then there would hardly be a reason to conduct research in the first place. A healthy discipline will have many false starts as it confronts the limits of present understanding. Innovation is the engine of discovery and is vital for a productive, effective scientific enterprise. However, innovative ideas become old news fast. Journal reviewers and editors may dismiss a new test of a published idea as unoriginal. The claim that \"we already know this\" belies the uncertainty of scientific evidence. Deciding the ideal balance of resourcing innovation versus verification is a question of research efficiency. How can we maximize the rate of research progress? Innovation points out paths that are possible; replication points out paths that are likely; progress relies on both. The ideal balance is a topic for investigation itself. Scientific incentives-funding, publication, or awards-can be tuned to encourage an optimal balance in the collective effort of discovery  (36, 37) . Progress occurs when existing expectations are violated and a surprising result spurs a new investigation. Replication can increase certainty when findings are reproduced and promote innovation when they are not. This project provides accumulating evidence for many findings in psychological research and suggests that there is still more work to do to verify whether we know what we think we know. \n",
            " Conclusion After this intensive effort to reproduce a sample of published psychological findings, how many of the effects have we established are true? Zero. And how many of the effects have we established are false? Zero. Is this a limitation of the project design? No. It is the reality of doing science, even if it is not appreciated in daily practice. Humans desire certainty, and science infrequently provides it. As much as we might wish it to be otherwise, a single study almost never provides definitive resolution for or against an effect and its explanation. The original studies examined here offered tentative evidence; the replications we conducted offered additional, confirmatory evidence. In some cases, the replications increase confidence in the reliability of the original results; in other cases, the replications suggest that more investigation is needed to establish the validity of the original findings. Scientific progress is a cumulative process of uncertainty reduction that can only succeed if science itself remains the greatest skeptic of its explanatory claims. The present results suggest that there is room to improve reproducibility in psychology. Any temptation to interpret these results as a defeat for psychology, or science more generally, must contend with the fact that this project demon-strates science behaving as it should. Hypotheses abound that the present culture in science may be negatively affecting the reproducibility of findings. An ideological response would discount the arguments, discredit the sources, and proceed merrily along. The scientific process is not ideological. Science does not always provide comfort for what we wish to be; it confronts us with what is. Moreover, as illustrated by the Transparency and Openness Promotion (TOP) Guidelines ( http://cos.io/top )  (37) , the research community is taking action already to improve the quality and credibility of the scientific literature. We conducted this project because we care deeply about the health of our discipline and believe in its promise for accumulating knowledge about human behavior that can advance the quality of the human condition. Reproducibility is central to that aim. Accumulating evidence is the scientific community's method of self-correction and is the best available option for achieving that ultimate goal: truth. P. Whitehead, C. Widmann, D. K. Williams, K. M. Williams, and H. Yi. Also, we thank the authors of the original research that was the subject of replication in this project. These authors were generous with their time, materials, and advice for improving the quality of each replication and identifying the strengths and limits of the outcomes. The authors of this work are listed alphabetically. This project was supported by the Center for Open Science and the Laura and John Arnold Foundation. The authors declare no financial conflict of interest with the reported research.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice that it worked ðŸ™‚"
      ],
      "metadata": {
        "id": "e2rSNoBvF_3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"You are a helpful friend and researcher who is expert in succinctly summarising information from academic papers.\"\n",
        "user_prompt = \"Can you tell me what political scientists can take from this study in psychology?\""
      ],
      "metadata": {
        "id": "k5TvjIbqGK0g"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the full user prompt which includes the academic paper!\n",
        "full_user_prompt = user_prompt + extracted_paper_elements\n",
        "\n",
        "# Make the API call\n",
        "response = openai_client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    top_p= .05,\n",
        "    temperature = 1.9,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": full_user_prompt}\n",
        "        ],\n",
        "    max_tokens = 80\n",
        "    )\n",
        "\n",
        "output_text = response.choices[0].message.content # take the output and extract the text response only\n",
        "\n",
        "print(output_text) # print the output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiyKFtelGXWx",
        "outputId": "2ad8f82e-5091-4ce4-9429-4bce09e88a8f",
        "collapsed": true
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The study \"Estimating the reproducibility of psychological science\" by the Open Science Collaboration provides several insights that political scientists can draw upon, particularly regarding research practices, the importance of replication, and the implications of reproducibility in scientific inquiry. Here are the key takeaways:\n",
            "\n",
            "1. **Reproducibility as a Core Principle**: Just as in psychology, reproducibility is essential in political science.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some GB notes:\n",
        "- Higher temperature more unrealistic things, like tokens from different languages.\n",
        "- top_p might prevent this a bit"
      ],
      "metadata": {
        "id": "6k5EljmChmNn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hands-on:\n",
        "Try to:\n",
        "\n",
        "\n",
        "1.   Ask about other study characteristics.\n",
        "2.   Play around with the hyperparameters we learned about earlier. How does it change the output?\n",
        "\n"
      ],
      "metadata": {
        "id": "XAV3PyTbP4_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##So what?\n",
        "All of this is pretty fun and cool, but it's also pretty accessible in the standard chat interface too. So let's build this into a programmatic workflow. Specifically, we're going build the workflow out to (i) read in a paper, (ii) use GROBID to extract the text from it, (iii) call an LLM to ask it to extract the paper's title and give a short summary, and (iv) save this information into a single csv file."
      ],
      "metadata": {
        "id": "SNf02tyXQElX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To do this, we're going to need the LLM to give us _structured output_ in each iteration: in other words, as a json file. Now, we could just ask it for json, but because of how LLMs work, there's a chance that this could fail at some point in a large workflow. So we will instead use the `pydantic` Python module, which is made specifically to do this!"
      ],
      "metadata": {
        "id": "JBAOplsT0UB3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The basic use of `pydantic` involves specifying a \"BaseModel\" which specifies the structure of the output we want from the LLM. Then we feed that structure to the LLM via the `response_format` argument to the LLM call, and clearly define to the model what this output should look like. We also slightly change how we call the LLM (harnessing the `beta` component of the call to the OpenAI client, which enables the use of structured output). Let's look at a simple example below:"
      ],
      "metadata": {
        "id": "wrjVK-Ab0peZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import BaseModel from pydantic, which we can use to structure the output of the LLM call\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# define the desired output, called CustomLLMOutput\n",
        "class CustomLLMOutput(BaseModel):\n",
        "  FirstLetter: str\n",
        "  LastLetter: str\n",
        "  NumberOfCharacters: int\n",
        "\n",
        "# define our simple prompt\n",
        "prompt = \"Hi! Your goal here is to return the FirstLetter of this text, and the LastLetter, as well as the total NumberOfCharacters in the text.\"\n",
        "\n",
        "# call the LLM, which CustomLLMOutput defined\n",
        "response = openai_client.beta.chat.completions.parse(\n",
        "    model = \"gpt-4o-mini\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    response_format = CustomLLMOutput\n",
        "    )\n",
        "\n",
        "# Parse the output\n",
        "response_content = response.choices[0].message.content\n",
        "\n",
        "# print the text response\n",
        "print(response_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCMcHG381AJE",
        "outputId": "ce281e44-6467-4e74-c1b5-9ca2e86d9543"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"FirstLetter\":\"H\",\"LastLetter\":\"t\",\"NumberOfCharacters\":104}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GB: Note by, yes in the API you can set seeds and stuff but it is not 100% but 99% then."
      ],
      "metadata": {
        "id": "VxSIW82plXnR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OK, so let's build out a full workflow then!\n",
        "#A workflow:\n",
        "In fact, we already created some functions that we can nicely slot into a looped process: specifically `read_with_grobid` and `extract_relevant_text`. Now we need to do something similar with the call to the LLM. Like this:"
      ],
      "metadata": {
        "id": "6ECOg8NR5dga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's define our BaseModel for the LLM call first\n",
        "class PaperSummary(BaseModel):\n",
        "  paper_title: str\n",
        "  paper_summary: str\n",
        "\n",
        "# and now let's define the LLM calling function\n",
        "def call_llm(paper_content):\n",
        "\n",
        "  # first we define our prompt, leaving a placeholder for the paper content to be inserted\n",
        "  prompt = (\n",
        "      f\"Your task is to extract relevant information from text of an academic paper.\"\n",
        "      f\"You specifically should extract (1) the paper's title, and (2) a short summary about the paper.\"\n",
        "      f\"Your output should consist of two columns: paper_title, and paper_summary. Your summary should be no more than 30 words each.\"\n",
        "      f\"Here's the paper content: \\n{paper_content}\"\n",
        "  )\n",
        "\n",
        "  # next, we call the LLM!\n",
        "  response = openai_client.beta.chat.completions.parse(\n",
        "    model = \"gpt-4o-mini\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    response_format = PaperSummary\n",
        "    )\n",
        "\n",
        "  # Then we'll parse the output\n",
        "  response_content = response.choices[0].message.content\n",
        "\n",
        "  # and finally we want to return the response\n",
        "  return response_content\n"
      ],
      "metadata": {
        "id": "1VwMThrG5vZh"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's just put it all together! We'll test it out on the paper from earlier to make sure there are no issues."
      ],
      "metadata": {
        "id": "Z-BeypFv6wVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1. Read in paper\n",
        "paper = read_with_grobid('/content/science.aac4716.pdf')\n",
        "\n",
        "# Step 2. Extract relevant content\n",
        "extracted_paper_elements = extract_relevant_text(paper)\n",
        "\n",
        "# Step 3. Call LLM\n",
        "llm_output = call_llm(extracted_paper_elements)\n",
        "\n",
        "# Print the output\n",
        "print(llm_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8cZfvn961zb",
        "outputId": "abc690b8-dad4-4286-862b-594f88e29249"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"paper_title\":\"Estimating the reproducibility of psychological science Open Science Collaboration\",\"paper_summary\":\"This study assesses the reproducibility of psychological research by replicating 100 studies, revealing significant declines in effect sizes and varied indicators of replication success.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Success! Now we want to run this on 5 papers. So we need to (i) wrap the process in a loop, and (ii) combine the outputs."
      ],
      "metadata": {
        "id": "uNTtDDe17Hwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, we list all files which have the word \"paper\" in their name\n",
        "import os # we import the os module to communicate with the operating system\n",
        "papers = [file for file in os.listdir() if \"paper\" in file]\n",
        "\n",
        "# Next, we create an empty list which we will save the output of the loop to\n",
        "paper_summaries = []\n",
        "\n",
        "# loop our workflow over every entry in papers, and save the output to paper_summaries\n",
        "for paper in papers:\n",
        "\n",
        "  # Step 1: read in paper\n",
        "  paper = read_with_grobid(paper)\n",
        "\n",
        "  # Step 2: extract relevant content\n",
        "  extracted_paper_elements = extract_relevant_text(paper)\n",
        "\n",
        "  # Step 3: Call LLM\n",
        "  llm_output = call_llm(extracted_paper_elements)\n",
        "\n",
        "  # Step 4: Add the output to the ppaer_summaries object\n",
        "  paper_summaries.append(llm_output)\n"
      ],
      "metadata": {
        "id": "8-c3LDId7OC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OK - let's tidy the output up slightly and see how it looks!"
      ],
      "metadata": {
        "id": "IdI7JoMx_OVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import a couple of libraries for nicer table formatting\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# unpack each entry based on its json formatting\n",
        "papers = [json.loads(item) for item in paper_summaries]\n",
        "\n",
        "# convert this to a data frame\n",
        "papers_df = pd.DataFrame(papers)\n",
        "\n",
        "# display the output as a table\n",
        "print(papers_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "Sgqxoiuz-r8H",
        "outputId": "721967eb-b40d-44fd-b367-06f2fceb6380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'paper_summaries' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-05e85ea2d870>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# unpack each entry based on its json formatting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpapers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpaper_summaries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# convert this to a data frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'paper_summaries' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extra content\n",
        "Below is some extra content not planned to be covered, or mentioned in the introductory part of the workshop."
      ],
      "metadata": {
        "id": "AKoVMyz_naw-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Simple RAG workflow"
      ],
      "metadata": {
        "id": "HUfuETaRngnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# general function to call OpenAI's embeddings model\n",
        "def get_embedding(text, model = \"text-embedding-3-large\"):\n",
        "    \"\"\"\n",
        "    Fetches embeddings from OpenAI API for a given text.\n",
        "    \"\"\"\n",
        "    response = openai_client.embeddings.create(input=text, model=model)\n",
        "    return np.array(response.data[0].embedding)"
      ],
      "metadata": {
        "id": "h5xI_VXzniib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some functions for tokenisation below."
      ],
      "metadata": {
        "id": "vzbSdrPsou9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken\n",
        "import nltk\n",
        "import tiktoken\n",
        "\n",
        "# Download NLTK data (required for tokenisation)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "\n",
        "# function for handling cases where sentences are not delineated by punctuation (will happen often with transcripts)\n",
        "def split_long_sentence(sentence, max_tokens, overlap_tokens, encoding):\n",
        "    \"\"\"\n",
        "    Splits a sentence that exceeds max_tokens into smaller chunks with an overlap,\n",
        "    ensuring that chunks do not cut words in half (i.e. they end at a token boundary\n",
        "    where the next token begins with a space).\n",
        "\n",
        "    Parameters:\n",
        "        sentence (str): The sentence to be split.\n",
        "        max_tokens (int): Maximum tokens allowed per chunk.\n",
        "        overlap_tokens (int): Number of tokens to overlap between subchunks.\n",
        "        encoding: The tiktoken encoding object.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: A list of text chunks from the sentence.\n",
        "    \"\"\"\n",
        "    tokens = encoding.encode(sentence)\n",
        "    # If the sentence is already short enough, return it as is.\n",
        "    if len(tokens) <= max_tokens:\n",
        "        return [sentence]\n",
        "\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(tokens):\n",
        "        # Set an initial end position.\n",
        "        end = start + max_tokens\n",
        "        # If we're not at the very end, try to adjust the cut so that the next token starts with a space.\n",
        "        if end < len(tokens):\n",
        "            # Decrease end until the token at position 'end' decodes to text that starts with a space.\n",
        "            while end > start + 1 and not encoding.decode([tokens[end]]).startswith(\" \"):\n",
        "                end -= 1\n",
        "        # If we couldn't find a boundary, fall back to the original end.\n",
        "        if end == start:\n",
        "            end = start + max_tokens\n",
        "\n",
        "        chunk_tokens = tokens[start:end]\n",
        "        chunk_text = encoding.decode(chunk_tokens)\n",
        "        chunks.append(chunk_text)\n",
        "\n",
        "        # If we've reached the end, break.\n",
        "        if end >= len(tokens):\n",
        "            break\n",
        "\n",
        "        # Set start for the next chunk with overlap.\n",
        "        start = end - overlap_tokens\n",
        "        if start < 0:\n",
        "            start = 0\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# function that extracts the chunks themselves based on token lengths\n",
        "def extract_chunks(transcript_text, max_tokens=1000, overlap_tokens=100, model=\"gpt-4o\"):\n",
        "    \"\"\"\n",
        "    Splits transcript text into chunks that start and end at sentence boundaries,\n",
        "    with optional overlapping tokens between chunks.\n",
        "\n",
        "    Parameters:\n",
        "        transcript_text (str): The input text to chunk.\n",
        "        max_tokens (int): Max number of tokens per chunk.\n",
        "        overlap_tokens (int): Target number of overlapping tokens between chunks.\n",
        "        model (str): Tokenizer model name.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: List of sentence-aligned chunks.\n",
        "    \"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(model)\n",
        "    tokenize = lambda text: encoding.encode(text)\n",
        "\n",
        "    # Step 1: Sentence segmentation\n",
        "    sentences = nltk.sent_tokenize(transcript_text)\n",
        "\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_tokens = 0\n",
        "    sentence_token_lengths = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence_tokens = tokenize(sentence)\n",
        "        sentence_len = len(sentence_tokens)\n",
        "\n",
        "        # If the sentence alone exceeds max_tokens, split it further\n",
        "        if sentence_len > max_tokens:\n",
        "            sub_sentences = split_long_sentence(sentence, max_tokens, overlap_tokens, encoding)\n",
        "            for sub in sub_sentences:\n",
        "                sub_len = len(tokenize(sub))\n",
        "                if current_tokens + sub_len > max_tokens:\n",
        "                    # Finalize chunk\n",
        "                    chunks.append(\" \".join(current_chunk))\n",
        "                    current_chunk = []\n",
        "                    current_tokens = 0\n",
        "                    sentence_token_lengths = []\n",
        "                current_chunk.append(sub)\n",
        "                current_tokens += sub_len\n",
        "                sentence_token_lengths.append(sub_len)\n",
        "            continue\n",
        "\n",
        "        # If adding this sentence would exceed the token limit, start new chunk\n",
        "        if current_tokens + sentence_len > max_tokens:\n",
        "            chunks.append(\" \".join(current_chunk))\n",
        "\n",
        "            # Apply overlap: backtrack through sentences until we hit overlap_tokens\n",
        "            overlap_chunk = []\n",
        "            overlap_count = 0\n",
        "            for sent, sent_len in zip(reversed(current_chunk), reversed(sentence_token_lengths)):\n",
        "                overlap_chunk.insert(0, sent)\n",
        "                overlap_count += sent_len\n",
        "                if overlap_count >= overlap_tokens:\n",
        "                    break\n",
        "\n",
        "            current_chunk = overlap_chunk.copy()\n",
        "            current_tokens = sum(tokenize(s).__len__() for s in current_chunk)\n",
        "            sentence_token_lengths = [len(tokenize(s)) for s in current_chunk]\n",
        "\n",
        "        # Append sentence\n",
        "        current_chunk.append(sentence)\n",
        "        current_tokens += sentence_len\n",
        "        sentence_token_lengths.append(sentence_len)\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(\" \".join(current_chunk))\n",
        "\n",
        "    return chunks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_e-gj6koukG",
        "outputId": "22da9e84-496d-4584-c4ab-ed1c60296998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions for embedding extraction and comparison below."
      ],
      "metadata": {
        "id": "itvoWcGGpA3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def get_embedding(text, model = \"text-embedding-3-small\"):\n",
        "    \"\"\"\n",
        "    Fetches embeddings from OpenAI API for a given text.\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "      raise ValueError(\"Text for embedding cannot be empty.\")\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "      raise ValueError(\"Text for embedding must be a non-empty string.\")\n",
        "    response = openai_client.embeddings.create(model=model, input=text)\n",
        "    embedding = np.array(response.data[0].embedding)\n",
        "    token_count = response.usage.total_tokens  # Extract token count from API response\n",
        "\n",
        "    return embedding, token_count\n",
        "\n",
        "def embed_paper(text, max_tokens, overlap_tokens):\n",
        "    \"\"\"\n",
        "    Extracts embeddings for each paragraph in the manuscript.\n",
        "    \"\"\"\n",
        "    paper_chunks = extract_chunks(text, max_tokens=max_tokens, overlap_tokens=overlap_tokens, model=\"gpt-4o\")\n",
        "    results = [get_embedding(p) for p in paper_chunks]\n",
        "    embeddings = [r[0] for r in results]\n",
        "    token_counts = [r[1] for r in results]\n",
        "\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        \"chunk\": paper_chunks,\n",
        "        \"embedding\": embeddings\n",
        "    })\n",
        "\n",
        "def retrieve_relevant_chunks(prompt, df, top_k=None, threshold=None):\n",
        "    \"\"\"\n",
        "    Retrieves the most relevant chunks for a given topic name embedding based on cosine similarity.\n",
        "\n",
        "    - If only top_k is defined, returns the top_k highest similarity paragraphs.\n",
        "    - If only threshold is defined, returns all paragraphs meeting the threshold.\n",
        "    - If both are defined, applies both criteria.\n",
        "    - If neither is defined, raises an error.\n",
        "    \"\"\"\n",
        "    if top_k is None and threshold is None:\n",
        "        raise ValueError(\"At least one of 'top_k' or 'threshold' must be specified.\")\n",
        "\n",
        "    topic_embedding = get_embedding(prompt)[0]\n",
        "\n",
        "    # Compute cosine similarity between query and all paragraph embeddings\n",
        "    similarities = cosine_similarity([topic_embedding], np.vstack(df[\"embedding\"]))[0]\n",
        "\n",
        "    # Add similarity scores to the DataFrame\n",
        "    df[\"similarity\"] = similarities\n",
        "    df_sorted = df.sort_values(by=\"similarity\", ascending=False)\n",
        "\n",
        "    # Apply filtering logic based on top_k and threshold\n",
        "    if threshold is not None:\n",
        "        df_sorted = df_sorted[df_sorted[\"similarity\"] >= threshold]  # Apply threshold filter\n",
        "\n",
        "    if top_k is not None:\n",
        "        df_sorted = df_sorted.head(top_k)  # Apply top_k limit\n",
        "\n",
        "    return df_sorted[[\"chunk\", \"similarity\"]]\n"
      ],
      "metadata": {
        "id": "NDlJXe6xpDDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "code for handling overlapping text between chunks."
      ],
      "metadata": {
        "id": "B3iBK7cspOSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this is specifically for checking if there is overlap between chunks, and joining them directly (without redundant overlap repeated) if so\n",
        "def find_overlap(chunk1, chunk2):\n",
        "    \"\"\"\n",
        "    Identifies the largest overlapping text at the end of chunk1 and the beginning of chunk2.\n",
        "\n",
        "    Parameters:\n",
        "        chunk1 (str): The first chunk of text.\n",
        "        chunk2 (str): The second chunk of text.\n",
        "\n",
        "    Returns:\n",
        "        str: The overlapping text if found, otherwise an empty string.\n",
        "    \"\"\"\n",
        "    min_overlap_length = 20  # Minimum number of characters for a valid overlap\n",
        "\n",
        "    # Iterate backwards from the end of chunk1 to find the largest overlap in chunk2\n",
        "    for i in range(len(chunk1)):\n",
        "        overlap_candidate = chunk1[i:]  # Take the ending substring of chunk1\n",
        "        if chunk2.startswith(overlap_candidate) and len(overlap_candidate) >= min_overlap_length:\n",
        "            return overlap_candidate\n",
        "    return \"\"\n",
        "\n",
        "def format_relevant_chunks(df):\n",
        "    \"\"\"\n",
        "    Formats relevant paragraphs into a structured text block for LLM input,\n",
        "    ensuring overlapping text between adjacent chunks is merged properly.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): A DataFrame containing a \"chunk\" column with text segments.\n",
        "\n",
        "    Returns:\n",
        "        str: A formatted text block with overlaps merged and non-overlapping chunks separated.\n",
        "    \"\"\"\n",
        "    df = df.sort_index()  # Sort the chunks by index\n",
        "    chunks = df[\"chunk\"].tolist()  # Extract chunks as a list\n",
        "\n",
        "    if not chunks:\n",
        "        return \"\"\n",
        "\n",
        "    formatted_text = chunks[0]  # Start with the first chunk\n",
        "\n",
        "    for i in range(1, len(chunks)):\n",
        "        overlap = find_overlap(formatted_text, chunks[i])\n",
        "\n",
        "        if overlap:\n",
        "            # Merge by removing duplicate overlap\n",
        "            formatted_text += chunks[i][len(overlap):]\n",
        "        else:\n",
        "            # Separate with \"... \\n\\n ...\"\n",
        "            formatted_text += \" ... \\n\\n ... \" + chunks[i]\n",
        "\n",
        "    return formatted_text"
      ],
      "metadata": {
        "id": "oJRlQ8ogpQbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "extract embeddings for paper:"
      ],
      "metadata": {
        "id": "y5C2SyZ8mTvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy again because when I re-run this from scratch I keep not having it imported\n",
        "import numpy as np\n",
        "\n",
        "# embed the formatted document and print the associated dataframe\n",
        "df_embeddings = embed_paper(extracted_paper_elements, max_tokens = 500, overlap_tokens = 100)\n",
        "df_embeddings"
      ],
      "metadata": {
        "id": "ffXJ3rIbpcVl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "outputId": "2ca6da48-8ed5-4e67-c491-9d6d1c32e9a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                chunk  \\\n",
              "0   Title: Estimating the reproducibility of psych...   \n",
              "1   Thirty-six percent of replications had signifi...   \n",
              "2   This project provides accumulating evidence fo...   \n",
              "3   Direct replication is the attempt to recreate ...   \n",
              "4   Potentially problematic practices include sele...   \n",
              "5   The units of analysis for inferences about rep...   \n",
              "6   Project coordinators facilitated matching arti...   \n",
              "7   The key result had to be represented as a sing...   \n",
              "8   The most common reasons for failure to match a...   \n",
              "9   These included characteristics of the original...   \n",
              "10  From this pool of available studies, replicati...   \n",
              "11  Using only the nonsignificant P values of the ...   \n",
              "12  Third, we computed the proportion of study-pai...   \n",
              "13  Exclusions (explanation provided in supplement...   \n",
              "14  Standard errors could only be computed if test...   \n",
              "15  Analysis of moderators We correlated the five ...   \n",
              "16  When there is no effect to detect, the null di...   \n",
              "17  Also, the replication \"succeeds\" when the resu...   \n",
              "18  One qualification about this result is the pos...   \n",
              "19  Considering significance testing, reproducibil...   \n",
              "20  Almost two thirds (20 of 32, 63%) of original ...   \n",
              "21  The latter factors certainly can influence rep...   \n",
              "22  Consistent with this expectation, most replica...   \n",
              "23  Reproducibility is not well understood because...   \n",
              "24  The ideal balance is a topic for investigation...   \n",
              "25  Science does not always provide comfort for wh...   \n",
              "\n",
              "                                            embedding  \n",
              "0   [0.050331443548202515, 0.01178510021418333, 0....  \n",
              "1   [0.04425464943051338, -0.0023916689679026604, ...  \n",
              "2   [0.04153410717844963, -0.0018653592560440302, ...  \n",
              "3   [0.036356888711452484, 0.0043677156791090965, ...  \n",
              "4   [0.040376920253038406, 0.010345174930989742, 0...  \n",
              "5   [0.016850758343935013, 0.0059136622585356236, ...  \n",
              "6   [0.028508516028523445, 0.0037176646292209625, ...  \n",
              "7   [0.02611692063510418, 0.019338591024279594, 0....  \n",
              "8   [0.016962390393018723, 0.028942249715328217, 0...  \n",
              "9   [0.027320412918925285, 0.005955172702670097, 0...  \n",
              "10  [0.03738851100206375, -0.004830995574593544, 0...  \n",
              "11  [0.021562064066529274, -0.03394116833806038, 0...  \n",
              "12  [0.04071827977895737, -0.01888895407319069, 0....  \n",
              "13  [0.02814759872853756, -0.015499881468713284, 0...  \n",
              "14  [0.03007425181567669, -0.007572266738861799, 0...  \n",
              "15  [0.02257361076772213, 0.008557644672691822, 0....  \n",
              "16  [0.026772739365696907, -0.023849690333008766, ...  \n",
              "17  [0.057230137288570404, -0.023440003395080566, ...  \n",
              "18  [0.03390921652317047, 0.008405360393226147, 0....  \n",
              "19  [0.021472038701176643, -0.01443508267402649, 0...  \n",
              "20  [0.048780594021081924, 0.008947338908910751, 0...  \n",
              "21  [0.05014503374695778, 0.014464913867413998, 0....  \n",
              "22  [0.04350152984261513, 0.008282382041215897, 0....  \n",
              "23  [0.05198070779442787, 0.006784346420317888, 0....  \n",
              "24  [0.04588186368346214, 0.010664106346666813, 0....  \n",
              "25  [0.05950440093874931, 0.03138993680477142, 0.0...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7084035c-345f-4008-ab4b-113d252b527d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chunk</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Title: Estimating the reproducibility of psych...</td>\n",
              "      <td>[0.050331443548202515, 0.01178510021418333, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Thirty-six percent of replications had signifi...</td>\n",
              "      <td>[0.04425464943051338, -0.0023916689679026604, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This project provides accumulating evidence fo...</td>\n",
              "      <td>[0.04153410717844963, -0.0018653592560440302, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Direct replication is the attempt to recreate ...</td>\n",
              "      <td>[0.036356888711452484, 0.0043677156791090965, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Potentially problematic practices include sele...</td>\n",
              "      <td>[0.040376920253038406, 0.010345174930989742, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The units of analysis for inferences about rep...</td>\n",
              "      <td>[0.016850758343935013, 0.0059136622585356236, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Project coordinators facilitated matching arti...</td>\n",
              "      <td>[0.028508516028523445, 0.0037176646292209625, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The key result had to be represented as a sing...</td>\n",
              "      <td>[0.02611692063510418, 0.019338591024279594, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The most common reasons for failure to match a...</td>\n",
              "      <td>[0.016962390393018723, 0.028942249715328217, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>These included characteristics of the original...</td>\n",
              "      <td>[0.027320412918925285, 0.005955172702670097, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>From this pool of available studies, replicati...</td>\n",
              "      <td>[0.03738851100206375, -0.004830995574593544, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Using only the nonsignificant P values of the ...</td>\n",
              "      <td>[0.021562064066529274, -0.03394116833806038, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Third, we computed the proportion of study-pai...</td>\n",
              "      <td>[0.04071827977895737, -0.01888895407319069, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Exclusions (explanation provided in supplement...</td>\n",
              "      <td>[0.02814759872853756, -0.015499881468713284, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Standard errors could only be computed if test...</td>\n",
              "      <td>[0.03007425181567669, -0.007572266738861799, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Analysis of moderators We correlated the five ...</td>\n",
              "      <td>[0.02257361076772213, 0.008557644672691822, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>When there is no effect to detect, the null di...</td>\n",
              "      <td>[0.026772739365696907, -0.023849690333008766, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Also, the replication \"succeeds\" when the resu...</td>\n",
              "      <td>[0.057230137288570404, -0.023440003395080566, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>One qualification about this result is the pos...</td>\n",
              "      <td>[0.03390921652317047, 0.008405360393226147, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Considering significance testing, reproducibil...</td>\n",
              "      <td>[0.021472038701176643, -0.01443508267402649, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Almost two thirds (20 of 32, 63%) of original ...</td>\n",
              "      <td>[0.048780594021081924, 0.008947338908910751, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>The latter factors certainly can influence rep...</td>\n",
              "      <td>[0.05014503374695778, 0.014464913867413998, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Consistent with this expectation, most replica...</td>\n",
              "      <td>[0.04350152984261513, 0.008282382041215897, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Reproducibility is not well understood because...</td>\n",
              "      <td>[0.05198070779442787, 0.006784346420317888, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>The ideal balance is a topic for investigation...</td>\n",
              "      <td>[0.04588186368346214, 0.010664106346666813, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Science does not always provide comfort for wh...</td>\n",
              "      <td>[0.05950440093874931, 0.03138993680477142, 0.0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7084035c-345f-4008-ab4b-113d252b527d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7084035c-345f-4008-ab4b-113d252b527d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7084035c-345f-4008-ab4b-113d252b527d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4beba243-fd17-45a7-aeb4-33807ba5dd5b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4beba243-fd17-45a7-aeb4-33807ba5dd5b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4beba243-fd17-45a7-aeb4-33807ba5dd5b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_131666bf-aef0-4e08-8d19-bfc7583a820e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_embeddings')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_131666bf-aef0-4e08-8d19-bfc7583a820e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_embeddings');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_embeddings",
              "summary": "{\n  \"name\": \"df_embeddings\",\n  \"rows\": 26,\n  \"fields\": [\n    {\n      \"column\": \"chunk\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"The most common reasons for failure to match an article with a team were feasibility constraints for conducting the research. Of the 47 articles from the eligible pool that were not claimed, six (13%) had been deemed infeasible to replicate because of time, resources, instrumentation, dependence on historical events, or hard-to-access samples. The remaining 41 (87%) were eligible but not claimed. These often required specialized samples (such as macaques or people with autism), resources (such as eye tracking machines or functional magnetic resonance imaging), or knowledge making them difficult to match with teams. Aggregate data preparation Each replication team conducted the study, analyzed their data, wrote their summary report, and completed a checklist of requirements for sharing the materials and data. Then, independent reviewers and analysts conducted a projectwide audit of all individual projects, materials, data, and reports. A description of this review is available on the OSF ( https://osf.io/xtine ). Moreover, to maximize reproducibility and accuracy, the analyses for every replication study were reproduced by another analyst independent of the replication team using the R statistical programming language and a standardized analytic format. A controller R script was created to regenerate the entire analysis of every study and recreate the master data file. This R script, available at  https://osf.io/fkmwg , can be executed to reproduce the results of the individual studies. A comprehensive description of this reanalysis process is available publicly ( https://osf.io/a2eyg ). Measures and moderators We assessed features of the original study and replication as possible correlates of reproducibility and conducted exploratory analyses to inspire further investigation. These included characteristics of the original study such as the publishing journal; original effect size, P value, and sample size; experience and expertise of the original research team; importance of the effect, with indicators such as the citation impact of the article; and rated surprisingness of the effect. We also assessed characteristics of the replication such as statistical power and sample size, experience and expertise of the replication team, independently assessed challenge of conducting an effective replication, and self-assessed quality of the replication effort. Variables such as the P value indicate the statistical strength of evidence given the null hypothesis, and variables such as \\\"effect surprisingness\\\" and \\\"expertise of the team\\\" indicate qualities of the topic of study and the teams studying it, respectively.\",\n          \"When there is no effect to detect, the null distribution of P values is uniform. This distribution deviated slightly from uniform with positive skew, however, suggesting that at least one replication could be a false negative, c 2 (128) = 155.83, P = 0.048. Nonetheless, the wide distribution of P values suggests against insufficient power as the only explanation for failures to replicate. A scatterplot of original compared with replication study P values is shown in Fig. 2 . Evaluating replication effect against original effect size A complementary method for evaluating replication is to test whether the original effect size is within the 95% CI of the effect size estimate from the replication. For the subset of 73 studies in which the standard error of the correlation could be computed, 30 (41.1%) of the replication CIs contained the original effect size (significantly lower than the expected value of 78.5%, P < 0.001) (supplementary materials). For 22 studies using other test statistics [F(df 1 > 1, df 2 ) and c 2 ], 68.2% of CIs contained the effect size of the original study. Overall, this analysis suggests a 47.4% replication success rate. This method addresses the weakness of the first test that a replication in the same direction and a P value of 0.06 may not be significantly different from the original result. However, the method will also indicate that a replication \\\"fails\\\" when the direction of the effect is the same but the replication effect size is significantly smaller than the original effect size  (29) . Also, the replication \\\"succeeds\\\" when the result is near zero but not estimated with sufficiently high precision to be distinguished from the original effect size. Comparing original and replication effect sizes Comparing the magnitude of the original and replication effect sizes avoids special emphasis on P values. Overall, original study effect sizes (M = 0.403, SD = 0.188) were reliably larger than replication effect sizes (M = 0.197, SD = 0.257), Wilcoxon's W = 7137, P < 0.001.\",\n          \"Title: Estimating the reproducibility of psychological science Open Science Collaboration*\\n\\nAbstract: \\n INTRODUCTION: Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error. RATIONALE: There is concern about the rate and predictors of reproducibility, but limited evidence. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a pre-RESEARCH \\n\\n\\nBody:\\n\\n viously observed finding and is the means of establishing reproducibility of a finding with new data. We conducted a large-scale, collaborative effort to obtain an initial estimate of the reproducibility of psychological science. RESULTS  :  We conducted replications of 100 experimental and correlational studies published in three psychology journals using highpowered designs and original materials when available. There is no single standard for evaluating replication success. Here, we evaluated reproducibility using significance and P values, effect sizes, subjective assessments of replication teams, and meta-analysis of effect sizes. The mean effect size (r) of the replication effects (M r = 0.197, SD = 0.257) was half the magnitude of the mean effect size of the original effects (M r = 0.403, SD = 0.188), representing a substantial decline. Ninety-seven percent of original studies had significant results (P < .05). Thirty-six percent of replications had significant results; 47% of original effect sizes were in the 95% confidence interval of the replication effect size; 39% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams. CONCLUSION: No single indicator sufficiently describes replication success, and the five indicators examined here are not the only ways to evaluate reproducibility.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embedding\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "define prompt and extract embeddings:"
      ],
      "metadata": {
        "id": "EwlIdXDKmWfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_definition_info = \"The sample size, which is related to the number of participants which are reported in the manuscript.\""
      ],
      "metadata": {
        "id": "KEkn9RVznnC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_embedding = pd.DataFrame(get_embedding(prompt_definition_info)[0])\n",
        "print(prompt_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsNX89L0bRFk",
        "outputId": "646d34d5-0247-43bb-8a5f-2b30a7189808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             0\n",
            "0     0.023430\n",
            "1    -0.013261\n",
            "2     0.041532\n",
            "3    -0.003199\n",
            "4    -0.004277\n",
            "...        ...\n",
            "1531 -0.005394\n",
            "1532 -0.016504\n",
            "1533 -0.001266\n",
            "1534  0.009445\n",
            "1535  0.019909\n",
            "\n",
            "[1536 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "run RAG process:"
      ],
      "metadata": {
        "id": "5Hs90tjjmYxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "relevant_paragraphs = retrieve_relevant_chunks(prompt = prompt_definition_info,\n",
        "                                               df = df_embeddings,\n",
        "                                               top_k = 5)"
      ],
      "metadata": {
        "id": "4RSDbXzAcRgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relevant_paragraphs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dh0hUC7lccGm",
        "outputId": "16305dac-b926-4876-afc8-20d1826a77c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                chunk  similarity\n",
              "6   Project coordinators facilitated matching arti...    0.470970\n",
              "12  Third, we computed the proportion of study-pai...    0.447195\n",
              "13  Exclusions (explanation provided in supplement...    0.440072\n",
              "9   These included characteristics of the original...    0.429687\n",
              "8   The most common reasons for failure to match a...    0.425096"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13131de2-f3a4-42ca-b7a3-a06f94015bc6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chunk</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Project coordinators facilitated matching arti...</td>\n",
              "      <td>0.470970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Third, we computed the proportion of study-pai...</td>\n",
              "      <td>0.447195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Exclusions (explanation provided in supplement...</td>\n",
              "      <td>0.440072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>These included characteristics of the original...</td>\n",
              "      <td>0.429687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The most common reasons for failure to match a...</td>\n",
              "      <td>0.425096</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13131de2-f3a4-42ca-b7a3-a06f94015bc6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-13131de2-f3a4-42ca-b7a3-a06f94015bc6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-13131de2-f3a4-42ca-b7a3-a06f94015bc6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7ecf4681-5d49-484a-b637-99c2fe1c5c1c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7ecf4681-5d49-484a-b637-99c2fe1c5c1c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7ecf4681-5d49-484a-b637-99c2fe1c5c1c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_916475e5-c87a-4d76-954a-3c880b1218b1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('relevant_paragraphs')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_916475e5-c87a-4d76-954a-3c880b1218b1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('relevant_paragraphs');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "relevant_paragraphs",
              "summary": "{\n  \"name\": \"relevant_paragraphs\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"chunk\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Third, we computed the proportion of study-pairs in which the effect of the original study was stronger than in the replication study and tested the hypothesis that this proportion is 0.5. For this test, we included findings for which effect size measures were available but no correlation coefficient could be computed (for example, if a regression coefficient was reported but not its test statistic). Fourth, we calculated \\\"coverage,\\\" or the proportion of study-pairs in which the effect of the original study was in the CI of the effect of the replication study, and compared this with the expected proportion using a goodness-of-fit c 2 test. We carried SCIENCE sciencemag.org 28 AUGUST 2015 \\u2022 VOL 349 ISSUE 6251 aac4716-3 Table  2 . Spearman's rank-order correlations of reproducibility indicators with summary original and replication study characteristics. Effect size difference computed after converting r to Fisher's z. df/N refers to the information on which the test of the effect was based (for example, df of t test, denominator df of F test, sample size -3 of correlation, and sample size for z and c 2 ). Four original results had P values slightly higher than 0.05 but were considered positive results in the original article and are treated that way here. Exclusions (explanation provided in supplementary materials, A3) are \\\"replications P < .05\\\" (3 original nulls excluded; n = 97 studies), \\\"effect size difference\\\" (3 excluded; n = 97 studies); \\\"meta-analytic mean estimates\\\" (27 excluded; n = 73 studies); and, \\\"percent original effect size within replication 95% CI\\\" (5 excluded, n = 95 studies). 1 . Summary of reproducibility rates and effect sizes for original and replication studies overall and by journal/discipline. df/N refers to the information on which the test of the effect was based (for example, df of t test, denominator df of F test, sample size -3 of correlation, and sample size for z and c 2 ). Four original results had P values slightly higher than 0.05 but were considered positive results in the original article and are treated that way here.\",\n          \"The most common reasons for failure to match an article with a team were feasibility constraints for conducting the research. Of the 47 articles from the eligible pool that were not claimed, six (13%) had been deemed infeasible to replicate because of time, resources, instrumentation, dependence on historical events, or hard-to-access samples. The remaining 41 (87%) were eligible but not claimed. These often required specialized samples (such as macaques or people with autism), resources (such as eye tracking machines or functional magnetic resonance imaging), or knowledge making them difficult to match with teams. Aggregate data preparation Each replication team conducted the study, analyzed their data, wrote their summary report, and completed a checklist of requirements for sharing the materials and data. Then, independent reviewers and analysts conducted a projectwide audit of all individual projects, materials, data, and reports. A description of this review is available on the OSF ( https://osf.io/xtine ). Moreover, to maximize reproducibility and accuracy, the analyses for every replication study were reproduced by another analyst independent of the replication team using the R statistical programming language and a standardized analytic format. A controller R script was created to regenerate the entire analysis of every study and recreate the master data file. This R script, available at  https://osf.io/fkmwg , can be executed to reproduce the results of the individual studies. A comprehensive description of this reanalysis process is available publicly ( https://osf.io/a2eyg ). Measures and moderators We assessed features of the original study and replication as possible correlates of reproducibility and conducted exploratory analyses to inspire further investigation. These included characteristics of the original study such as the publishing journal; original effect size, P value, and sample size; experience and expertise of the original research team; importance of the effect, with indicators such as the citation impact of the article; and rated surprisingness of the effect. We also assessed characteristics of the replication such as statistical power and sample size, experience and expertise of the replication team, independently assessed challenge of conducting an effective replication, and self-assessed quality of the replication effort. Variables such as the P value indicate the statistical strength of evidence given the null hypothesis, and variables such as \\\"effect surprisingness\\\" and \\\"expertise of the team\\\" indicate qualities of the topic of study and the teams studying it, respectively.\",\n          \"Exclusions (explanation provided in supplementary materials, A3) are \\\"replications P < .05\\\" (3 original nulls excluded; n = 97 studies), \\\"effect size difference\\\" (3 excluded; n = 97 studies); \\\"meta-analytic mean estimates\\\" (27 excluded; n = 73 studies); and, \\\"percent original effect size within replication 95% CI\\\" (5 excluded, n = 95 studies). 1 . Summary of reproducibility rates and effect sizes for original and replication studies overall and by journal/discipline. df/N refers to the information on which the test of the effect was based (for example, df of t test, denominator df of F test, sample size -3 of correlation, and sample size for z and c 2 ). Four original results had P values slightly higher than 0.05 but were considered positive results in the original article and are treated that way here. Exclusions (explanation provided in supplementary materials, A3) are \\\"replications P < 0.05\\\" (3 original nulls excluded; n = 97 studies); \\\"mean original and replication effect sizes\\\" (3 excluded; n = 97 studies); \\\"meta-analytic mean estimates\\\" (27 excluded; n = 73 studies); \\\"percent meta-analytic (P < 0.05)\\\" (25 excluded; n = 75 studies); and, \\\"percent original effect size within replication 95% CI\\\" (5 excluded, n = 95 studies). out this test on the subset of study pairs in which both the correlation coefficient and its standard error could be computed [we refer to this data set as the meta-analytic (MA) subset]. Standard errors could only be computed if test statistics were r, t, or F(1,df 2 ). The expected proportion is the sum over expected probabilities across studypairs. The test assumes the same population effect size for original and replication study in the same study-pair. For those studies that tested the effect with F(df 1 > 1, df 2 ) or c 2 , we verified coverage using other statistical procedures (computational details are provided in the supplementary materials).\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"similarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.018065709195999403,\n        \"min\": 0.425095920680185,\n        \"max\": 0.47096986519325434,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.44719458015203506,\n          0.425095920680185,\n          0.44007190314510936\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating a simple classifier\n",
        "Imagine we want to use an LLM to classify a text as one of 5 categories. We could just instruct it in its prompt to only ever return one of these 5 categories - this works well in 99% of cases. But, depending on our workflow, that 1% of cases might actually break the entire process! So we can actually alter the token probabilities through the `logit_bias` parameter, such that only the tokens we select are actually possible to be generated."
      ],
      "metadata": {
        "id": "Y7uVqOI-J5SO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "# Get tokenizer\n",
        "enc = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
        "\n",
        "system_prompt = \"Your job is to classify text as one of three categories: positive, negative, or neutral.\"\n",
        "user_prompt_text = \"I'm not angry. I'm not mad. I don't even care. I'm just....so disappointed. I genuinely cannot believe you've done this to me.\"\n",
        "\n",
        "\n",
        "# Make the API call\n",
        "response = openai_client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": \"Here is the text to classify:\\n\" + user_prompt_text}\n",
        "        ],\n",
        "    logit_bias = {\n",
        "        enc.encode(\"positive\")[0]: 100,\n",
        "        enc.encode(\"negative\")[0]: 100,\n",
        "        enc.encode(\"neutral\")[0]: 100\n",
        "    },\n",
        "    max_tokens = 1 # add this to make sure we just get the single classification! (it would not have a stop character otherwise)\n",
        "    )\n",
        "\n",
        "output_text = response.choices[0].message.content # take the output and extract the text response only\n",
        "\n",
        "print(output_text) # print the output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2Jwo73GKPEL",
        "outputId": "be9aa67f-bc96-4b9d-fe2e-0b78105f81db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively, we can also use OpenAIâ€™s _function-calling_ feature, where we specify a function whose arguments are constrained by a schema (e.g., allowing only a fixed set of labels). This offers an even harder form of output control compared to the logit_bias approach. While logit_bias can nudge the model toward certain tokens, it does not guarantee valid output and may occasionally result in refusals. In contrast, the function-calling approach guarantees a structured response that conforms to the schema, provided the model chooses to call the function. If we want to force the model to call the function every time, we can explicitly set function_call={\"name\": \"classify_sentiment\"} to avoid relying on the modelâ€™s judgment."
      ],
      "metadata": {
        "id": "Tn5Bza6fN_Mz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a specification of the function which will be called by the model\n",
        "classifier_function_specification = [\n",
        "    {\n",
        "        \"name\": \"classify_sentiment\",\n",
        "        \"description\": \"Classify the sentiment of the given text as positive, neutral, or negative.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"label\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"enum\": [\"positive\", \"neutral\", \"negative\"]\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"label\"]\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# call the LLM\n",
        "response = openai_client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": \"Please classify the following text:\\n\" + user_prompt_text}\n",
        "    ],\n",
        "    functions=classifier_function_specification,\n",
        "    function_call={\"name\": \"classify_sentiment\"}\n",
        ")\n",
        "\n",
        "# Access function response (note: different than the text response)\n",
        "function_output = response.choices[0].message.function_call.arguments\n",
        "\n",
        "print(function_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxTHrB_mOFGs",
        "outputId": "174edcf8-ffa2-4349-a586-bfe6cc12ab79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"label\":\"negative\"}\n"
          ]
        }
      ]
    }
  ]
}